{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.document_loaders.text.TextLoader at 0x78da3cdc4920>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Text Loader\n",
    "\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "loader = TextLoader('speech.txt')\n",
    "loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'speech.txt'}, page_content='The MIT License (MIT)\\n#\\n# Copyright (c) 2015-2020 Dylan Araps\\n#\\n# Permission is hereby granted, free of charge, to any person obtaining a copy\\n# of this software and associated documentation files (the \"Software\"), to deal\\n# in the Software without restriction, including without limitation the rights\\n# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\n# copies of the Software, and to permit persons to whom the Software is\\n# furnished to do so, subject to the following conditions:\\n#\\n# The above copyright notice and this permission notice shall be included in all\\n# copies or substantial portions of the Software.\\n#\\n# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\n# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\n# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\n# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\n# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\n# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\n# SOFTWARE.')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_document  = loader.load()\n",
    "text_document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'example.pdf', 'page': 0, 'page_label': '1'}, page_content='Comparison:\\n \\nMatplotlib\\n \\nvs\\n \\nSeaborn\\n \\nvs\\n \\nGraphviz\\n \\nThese\\n \\nthree\\n \\nlibraries\\n \\nserve\\n \\ndifferent\\n \\npurposes\\n \\nin\\n \\ndata\\n \\nvisualization:\\n \\n \\nUse\\n \\nCases\\n \\n●\\n \\nMatplotlib\\n:\\n \\nGreat\\n \\nfor\\n \\ngeneral-purpose\\n \\nplots,\\n \\nhighly\\n \\ncustomizable\\n \\nbut\\n \\nrequires\\n \\nmore\\n \\ncode.\\n \\n●\\n \\nSeaborn\\n:\\n \\nBest\\n \\nfor\\n \\nstatistical\\n \\nvisualizations\\n \\nwith\\n \\nminimal\\n \\ncode\\n \\nand\\n \\nbetter\\n \\naesthetics.\\n \\n●\\n \\nGraphviz\\n:\\n \\nIdeal\\n \\nfor\\n \\ntree\\n \\nstructures,\\n \\ndecision\\n \\ntrees,\\n \\nflowcharts,\\n \\nand\\n \\nnetwork\\n \\ngraphs.\\nFeature\\n \\nMatplotlib\\n \\nSeaborn\\n \\nGraphviz\\n \\nPrimary\\n \\nUse\\n \\nGeneral-purpose\\n \\nplotting\\n \\nStatistical\\n \\ndata\\n \\nvisualization\\n \\nGraph-based\\n \\n(nodes\\n \\n&\\n \\nedges)\\n \\nvisualization\\n \\nComplexity\\n \\nModerate\\n \\n(requires\\n \\nsome\\n \\nsetup)\\n \\nEasier\\n \\n(built\\n \\non\\n \\nMatplotlib)\\n \\nSpecialized\\n \\nfor\\n \\ngraph\\n \\nstructures\\n \\nCustomization\\n \\nHighly\\n \\ncustomizable\\n \\nHigh\\n \\nbut\\n \\nbuilt-in\\n \\nstyles\\n \\nsimplify\\n \\ndesign\\n \\nCustomizable\\n \\nbut\\n \\nfor\\n \\nspecific\\n \\nuse\\n \\ncases\\n \\nPerformance\\n \\nEfficient\\n \\nfor\\n \\nmost\\n \\nplotting\\n \\nneeds\\n \\nSimilar\\n \\nto\\n \\nMatplotlib\\n \\nEfficient\\n \\nfor\\n \\ngraph\\n \\nstructures\\n \\nBest\\n \\nFor\\n \\nLine\\n \\ncharts,\\n \\nbar\\n \\ncharts,\\n \\nhistograms,\\n \\nscatter\\n \\nplots\\n \\nHeatmaps,\\n \\ncorrelation\\n \\nmatrices,\\n \\ncategorical\\n \\nplots\\n \\nFlowcharts,\\n \\ndecision\\n \\ntrees,\\n \\nnetwork\\n \\ngraphs\\n \\nDependencies\\n \\nStandalone\\n \\nBuilt\\n \\non\\n \\nMatplotlib\\n \\nRequires\\n \\nGraphviz\\n \\ninstallation\\n \\nEase\\n \\nof\\n \\nUse\\n \\nModerate\\n \\nEasier\\n \\ndue\\n \\nto\\n \\nbuilt-in\\n \\nthemes\\n \\nRequires\\n \\nlearning\\n \\nGraphviz’s\\n \\nDOT\\n \\nsyntax\\n '),\n",
       " Document(metadata={'source': 'example.pdf', 'page': 1, 'page_label': '2'}, page_content='SciPy\\n \\nSciPy\\n \\nis\\n \\na\\n \\ncollection\\n \\nof\\n \\nmathematical\\n \\nalgorithms\\n \\nand\\n \\nconvenience\\n \\nfunctions\\n \\nbuilt\\n \\non\\n \\nNumPy\\n \\n.\\n \\nIt\\n \\nadds\\n \\nsignificant\\n \\npower\\n \\nto\\n \\nPython\\n \\nby\\n \\nproviding\\n \\nthe\\n \\nuser\\n \\nwith\\n \\nhigh-level\\n \\ncommands\\n \\nand\\n \\nclasses\\n \\nfor\\n \\nmanipulating\\n \\nand\\n \\nvisualizing\\n \\ndata.\\n \\nSubpackages\\n \\ninclude:\\n \\ndifferentiate,\\n \\nsparse,\\n \\noptimize\\n \\netc.\\n \\n \\nNumPy\\n \\nvs\\n \\nSciPy\\n \\n \\n \\nFeature\\n \\nNumPy\\n \\nSciPy\\n \\nPurpose\\n \\nProvides\\n \\nefficient\\n \\narray\\n \\noperations\\n \\nand\\n \\nbasic\\n \\nnumerical\\n \\ncomputing\\n \\nBuilds\\n \\non\\n \\nNumPy\\n \\nwith\\n \\nadvanced\\n \\nscientific\\n \\ncomputing\\n \\nfunctions\\n \\nCore\\n \\nStrengths\\n \\nMulti-dimensional\\n \\narrays,\\n \\nlinear\\n \\nalgebra,\\n \\nrandom\\n \\nnumbers,\\n \\nbasic\\n \\nmath\\n \\noperations\\n \\nOptimized\\n \\nscientific\\n \\nalgorithms\\n \\nfor\\n \\noptimization,\\n \\nstatistics,\\n \\nsignal\\n \\nprocessing,\\n \\nand\\n \\nmore\\n \\nDependency\\n \\nStandalone\\n \\nlibrary\\n \\nDepends\\n \\non\\n \\nNumPy\\n \\nPerformance\\n \\nOptimized\\n \\nfor\\n \\narray\\n \\noperations\\n \\nUses\\n \\nNumPy\\n \\nbut\\n \\nadds\\n \\nmore\\n \\ncomputationally\\n \\nintensive\\n \\noperations\\n ')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "file_path = \"example.pdf\"\n",
    "loader = PyPDFLoader(file_path)\n",
    "docs = loader.load()\n",
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.documents.base.Document"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='\\n\\n      LLM Powered Autonomous Agents\\n    \\nDate: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\\n\\n\\nBuilding agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview#\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\\nTree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\\nAnother quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into “Problem PDDL”, then (2) requests a classical planner to generate a PDDL plan based on an existing “Domain PDDL”, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\\nSelf-Reflection#\\nSelf-reflection is a vital aspect that allows autonomous agents to improve iteratively by refining past action decisions and correcting previous mistakes. It plays a crucial role in real-world tasks where trial and error are inevitable.\\nReAct (Yao et al. 2023) integrates reasoning and acting within LLM by extending the action space to be a combination of task-specific discrete actions and the language space. The former enables LLM to interact with the environment (e.g. use Wikipedia search API), while the latter prompting LLM to generate reasoning traces in natural language.\\nThe ReAct prompt template incorporates explicit steps for LLM to think, roughly formatted as:\\nThought: ...\\nAction: ...\\nObservation: ...\\n... (Repeated many times)\\n\\nFig. 2.  Examples of reasoning trajectories for knowledge-intensive tasks (e.g. HotpotQA, FEVER) and decision-making tasks (e.g. AlfWorld Env, WebShop). (Image source: Yao et al. 2023).\\nIn both experiments on knowledge-intensive tasks and decision-making tasks, ReAct works better than the Act-only baseline where Thought: … step is removed.\\nReflexion (Shinn & Labash 2023) is a framework to equip agents with dynamic memory and self-reflection capabilities to improve reasoning skills. Reflexion has a standard RL setup, in which the reward model provides a simple binary reward and the action space follows the setup in ReAct where the task-specific action space is augmented with language to enable complex reasoning steps. After each action $a_t$, the agent computes a heuristic $h_t$ and optionally may decide to reset the environment to start a new trial depending on the self-reflection results.\\n\\nFig. 3. Illustration of the Reflexion framework. (Image source: Shinn & Labash, 2023)\\nThe heuristic function determines when the trajectory is inefficient or contains hallucination and should be stopped. Inefficient planning refers to trajectories that take too long without success. Hallucination is defined as encountering a sequence of consecutive identical actions that lead to the same observation in the environment.\\nSelf-reflection is created by showing two-shot examples to LLM and each example is a pair of (failed trajectory, ideal reflection for guiding future changes in the plan). Then reflections are added into the agent’s working memory, up to three, to be used as context for querying LLM.\\n\\nFig. 4. Experiments on AlfWorld Env and HotpotQA. Hallucination is a more common failure than inefficient planning in AlfWorld. (Image source: Shinn & Labash, 2023)\\nChain of Hindsight (CoH; Liu et al. 2023) encourages the model to improve on its own outputs by explicitly presenting it with a sequence of past outputs, each annotated with feedback. Human feedback data is a collection of $D_h = \\\\{(x, y_i , r_i , z_i)\\\\}_{i=1}^n$, where $x$ is the prompt, each $y_i$ is a model completion, $r_i$ is the human rating of $y_i$, and $z_i$ is the corresponding human-provided hindsight feedback. Assume the feedback tuples are ranked by reward, $r_n \\\\geq r_{n-1} \\\\geq \\\\dots \\\\geq r_1$ The process is supervised fine-tuning where the data is a sequence in the form of $\\\\tau_h = (x, z_i, y_i, z_j, y_j, \\\\dots, z_n, y_n)$, where $\\\\leq i \\\\leq j \\\\leq n$. The model is finetuned to only predict $y_n$ where conditioned on the sequence prefix, such that the model can self-reflect to produce better output based on the feedback sequence. The model can optionally receive multiple rounds of instructions with human annotators at test time.\\nTo avoid overfitting, CoH adds a regularization term to maximize the log-likelihood of the pre-training dataset. To avoid shortcutting and copying (because there are many common words in feedback sequences), they randomly mask 0% - 5% of past tokens during training.\\nThe training dataset in their experiments is a combination of WebGPT comparisons, summarization from human feedback and human preference dataset.\\n\\nFig. 5. After fine-tuning with CoH, the model can follow instructions to produce outputs with incremental improvement in a sequence. (Image source: Liu et al. 2023)\\nThe idea of CoH is to present a history of sequentially improved outputs  in context and train the model to take on the trend to produce better outputs. Algorithm Distillation (AD; Laskin et al. 2023) applies the same idea to cross-episode trajectories in reinforcement learning tasks, where an algorithm is encapsulated in a long history-conditioned policy. Considering that an agent interacts with the environment many times and in each episode the agent gets a little better, AD concatenates this learning history and feeds that into the model. Hence we should expect the next predicted action to lead to better performance than previous trials. The goal is to learn the process of RL instead of training a task-specific policy itself.\\n\\nFig. 6. Illustration of how Algorithm Distillation (AD) works. (Image source: Laskin et al. 2023).\\nThe paper hypothesizes that any algorithm that generates a set of learning histories can be distilled into a neural network by performing behavioral cloning over actions. The history data is generated by a set of source policies, each trained for a specific task. At the training stage, during each RL run, a random task is sampled and a subsequence of multi-episode history is used for training, such that the learned policy is task-agnostic.\\nIn reality, the model has limited context window length, so episodes should be short enough to construct multi-episode history. Multi-episodic contexts of 2-4 episodes are necessary to learn a near-optimal in-context RL algorithm. The emergence of in-context RL requires long enough context.\\nIn comparison with three baselines, including ED (expert distillation, behavior cloning with expert trajectories instead of learning history), source policy (used for generating trajectories for distillation by UCB), RL^2 (Duan et al. 2017; used as upper bound since it needs online RL), AD demonstrates in-context RL with performance getting close to RL^2 despite only using offline RL and learns much faster than other baselines. When conditioned on partial training history of the source policy, AD also improves much faster than ED baseline.\\n\\nFig. 7. Comparison of AD, ED, source policy and RL^2 on environments that require memory and exploration. Only binary reward is assigned. The source policies are trained with A3C for \"dark\" environments and DQN for watermaze.(Image source: Laskin et al. 2023)\\nComponent Two: Memory#\\n(Big thank you to ChatGPT for helping me draft this section. I’ve learned a lot about the human brain and data structure for fast MIPS in my conversations with ChatGPT.)\\nTypes of Memory#\\nMemory can be defined as the processes used to acquire, store, retain, and later retrieve information. There are several types of memory in human brains.\\n\\n\\nSensory Memory: This is the earliest stage of memory, providing the ability to retain impressions of sensory information (visual, auditory, etc) after the original stimuli have ended. Sensory memory typically only lasts for up to a few seconds. Subcategories include iconic memory (visual), echoic memory (auditory), and haptic memory (touch).\\n\\n\\nShort-Term Memory (STM) or Working Memory: It stores information that we are currently aware of and needed to carry out complex cognitive tasks such as learning and reasoning. Short-term memory is believed to have the capacity of about 7 items (Miller 1956) and lasts for 20-30 seconds.\\n\\n\\nLong-Term Memory (LTM): Long-term memory can store information for a remarkably long time, ranging from a few days to decades, with an essentially unlimited storage capacity. There are two subtypes of LTM:\\n\\nExplicit / declarative memory: This is memory of facts and events, and refers to those memories that can be consciously recalled, including episodic memory (events and experiences) and semantic memory (facts and concepts).\\nImplicit / procedural memory: This type of memory is unconscious and involves skills and routines that are performed automatically, like riding a bike or typing on a keyboard.\\n\\n\\n\\n\\nFig. 8. Categorization of human memory.\\nWe can roughly consider the following mappings:\\n\\nSensory memory as learning embedding representations for raw inputs, including text, image or other modalities;\\nShort-term memory as in-context learning. It is short and finite, as it is restricted by the finite context window length of Transformer.\\nLong-term memory as the external vector store that the agent can attend to at query time, accessible via fast retrieval.\\n\\nMaximum Inner Product Search (MIPS)#\\nThe external memory can alleviate the restriction of finite attention span.  A standard practice is to save the embedding representation of information into a vector store database that can support fast maximum inner-product search (MIPS). To optimize the retrieval speed, the common choice is the approximate nearest neighbors (ANN)\\u200b algorithm to return approximately top k nearest neighbors to trade off a little accuracy lost for a huge speedup.\\nA couple common choices of ANN algorithms for fast MIPS:\\n\\nLSH (Locality-Sensitive Hashing): It introduces a hashing function such that similar input items are mapped to the same buckets with high probability, where the number of buckets is much smaller than the number of inputs.\\nANNOY (Approximate Nearest Neighbors Oh Yeah): The core data structure are random projection trees, a set of binary trees where each non-leaf node represents a hyperplane splitting the input space into half and each leaf stores one data point. Trees are built independently and at random, so to some extent, it mimics a hashing function. ANNOY search happens in all the trees to iteratively search through the half that is closest to the query and then aggregates the results. The idea is quite related to KD tree but a lot more scalable.\\nHNSW (Hierarchical Navigable Small World): It is inspired by the idea of small world networks where most nodes can be reached by any other nodes within a small number of steps; e.g. “six degrees of separation” feature of social networks. HNSW builds hierarchical layers of these small-world graphs, where the bottom layers contain the actual data points. The layers in the middle create shortcuts to speed up search. When performing a search, HNSW starts from a random node in the top layer and navigates towards the target. When it can’t get any closer, it moves down to the next layer, until it reaches the bottom layer. Each move in the upper layers can potentially cover a large distance in the data space, and each move in the lower layers refines the search quality.\\nFAISS (Facebook AI Similarity Search): It operates on the assumption that in high dimensional space, distances between nodes follow a Gaussian distribution and thus there should exist clustering of data points. FAISS applies vector quantization by partitioning the vector space into clusters and then refining the quantization within clusters. Search first looks for cluster candidates with coarse quantization and then further looks into each cluster with finer quantization.\\nScaNN (Scalable Nearest Neighbors): The main innovation in ScaNN is anisotropic vector quantization. It quantizes a data point $x_i$ to $\\\\tilde{x}_i$ such that the inner product $\\\\langle q, x_i \\\\rangle$ is as similar to the original distance of $\\\\angle q, \\\\tilde{x}_i$ as possible, instead of picking the closet quantization centroid points.\\n\\n\\nFig. 9. Comparison of MIPS algorithms, measured in recall@10. (Image source: Google Blog, 2020)\\nCheck more MIPS algorithms and performance comparison in ann-benchmarks.com.\\nComponent Three: Tool Use#\\nTool use is a remarkable and distinguishing characteristic of human beings. We create, modify and utilize external objects to do things that go beyond our physical and cognitive limits. Equipping LLMs with external tools can significantly extend the model capabilities.\\n\\nFig. 10. A picture of a sea otter using rock to crack open a seashell, while floating in the water. While some other animals can use tools, the complexity is not comparable with humans. (Image source: Animals using tools)\\nMRKL (Karpas et al. 2022), short for “Modular Reasoning, Knowledge and Language”, is a neuro-symbolic architecture for autonomous agents. A MRKL system is proposed to contain a collection of “expert” modules and the general-purpose LLM works as a router to route inquiries to the best suitable expert module. These modules can be neural (e.g. deep learning models) or symbolic (e.g. math calculator, currency converter, weather API).\\nThey did an experiment on fine-tuning LLM to call a calculator, using arithmetic as a test case. Their experiments showed that it was harder to solve verbal math problems than explicitly stated math problems because LLMs (7B Jurassic1-large model) failed to extract the right arguments for the basic arithmetic reliably. The results highlight when the external symbolic tools can work reliably, knowing when to and how to use the tools are crucial, determined by the LLM capability.\\nBoth TALM (Tool Augmented Language Models; Parisi et al. 2022) and Toolformer (Schick et al. 2023) fine-tune a LM to learn to use external tool APIs. The dataset is expanded based on whether a newly added API call annotation can improve the quality of model outputs. See more details in the “External APIs” section of Prompt Engineering.\\nChatGPT Plugins and OpenAI API  function calling are good examples of LLMs augmented with tool use capability working in practice. The collection of tool APIs can be provided by other developers (as in Plugins) or self-defined (as in function calls).\\nHuggingGPT (Shen et al. 2023) is a framework to use ChatGPT as the task planner to select models available in HuggingFace platform according to the model descriptions and summarize the response based on the execution results.\\n\\nFig. 11. Illustration of how HuggingGPT works. (Image source: Shen et al. 2023)\\nThe system comprises of 4 stages:\\n(1) Task planning: LLM works as the brain and parses the user requests into multiple tasks. There are four attributes associated with each task: task type, ID, dependencies, and arguments. They use few-shot examples to guide LLM to do task parsing and planning.\\nInstruction:\\n\\nThe AI assistant can parse user input to several tasks: [{\"task\": task, \"id\", task_id, \"dep\": dependency_task_ids, \"args\": {\"text\": text, \"image\": URL, \"audio\": URL, \"video\": URL}}]. The \"dep\" field denotes the id of the previous task which generates a new resource that the current task relies on. A special tag \"-task_id\" refers to the generated text image, audio and video in the dependency task with id as task_id. The task MUST be selected from the following options: {{ Available Task List }}. There is a logical relationship between tasks, please note their order. If the user input can\\'t be parsed, you need to reply empty JSON. Here are several cases for your reference: {{ Demonstrations }}. The chat history is recorded as {{ Chat History }}. From this chat history, you can find the path of the user-mentioned resources for your task planning.\\n\\n(2) Model selection: LLM distributes the tasks to expert models, where the request is framed as a multiple-choice question. LLM is presented with a list of models to choose from. Due to the limited context length, task type based filtration is needed.\\nInstruction:\\n\\nGiven the user request and the call command, the AI assistant helps the user to select a suitable model from a list of models to process the user request. The AI assistant merely outputs the model id of the most appropriate model. The output must be in a strict JSON format: \"id\": \"id\", \"reason\": \"your detail reason for the choice\". We have a list of models for you to choose from {{ Candidate Models }}. Please select one model from the list.\\n\\n(3) Task execution: Expert models execute on the specific tasks and log results.\\nInstruction:\\n\\nWith the input and the inference results, the AI assistant needs to describe the process and results. The previous stages can be formed as - User Input: {{ User Input }}, Task Planning: {{ Tasks }}, Model Selection: {{ Model Assignment }}, Task Execution: {{ Predictions }}. You must first answer the user\\'s request in a straightforward manner. Then describe the task process and show your analysis and model inference results to the user in the first person. If inference results contain a file path, must tell the user the complete file path.\\n\\n(4) Response generation: LLM receives the execution results and provides summarized results to users.\\nTo put HuggingGPT into real world usage, a couple challenges need to solve: (1) Efficiency improvement is needed as both LLM inference rounds and interactions with other models slow down the process; (2) It relies on a long context window to communicate over complicated task content; (3) Stability improvement of LLM outputs and external model services.\\nAPI-Bank (Li et al. 2023) is a benchmark for evaluating the performance of tool-augmented LLMs. It contains 53 commonly used API tools, a complete tool-augmented LLM workflow, and 264 annotated dialogues that involve 568 API calls. The selection of APIs is quite diverse, including search engines, calculator, calendar queries, smart home control, schedule management, health data management, account authentication workflow and more. Because there are a large number of APIs, LLM first has access to API search engine to find the right API to call and then uses the corresponding documentation to make a call.\\n\\nFig. 12. Pseudo code of how LLM makes an API call in API-Bank. (Image source: Li et al. 2023)\\nIn the API-Bank workflow, LLMs need to make a couple of decisions and at each step we can evaluate how accurate that decision is. Decisions include:\\n\\nWhether an API call is needed.\\nIdentify the right API to call: if not good enough, LLMs need to iteratively modify the API inputs (e.g. deciding search keywords for Search Engine API).\\nResponse based on the API results: the model can choose to refine and call again if results are not satisfied.\\n\\nThis benchmark evaluates the agent’s tool use capabilities at three levels:\\n\\nLevel-1 evaluates the ability to call the API. Given an API’s description, the model needs to determine whether to call a given API, call it correctly, and respond properly to API returns.\\nLevel-2 examines the ability to retrieve the API. The model needs to search for possible APIs that may solve the user’s requirement and learn how to use them by reading documentation.\\nLevel-3 assesses the ability to plan API beyond retrieve and call. Given unclear user requests (e.g. schedule group meetings, book flight/hotel/restaurant for a trip), the model may have to conduct multiple API calls to solve it.\\n\\nCase Studies#\\nScientific Discovery Agent#\\nChemCrow (Bran et al. 2023) is a domain-specific example in which LLM is augmented with 13 expert-designed tools to accomplish tasks across organic synthesis, drug discovery, and materials design. The workflow, implemented in LangChain, reflects what was previously described in the ReAct and MRKLs and combines CoT reasoning with tools relevant to the tasks:\\n\\nThe LLM is provided with a list of tool names, descriptions of their utility, and details about the expected input/output.\\nIt is then instructed to answer a user-given prompt using the tools provided when necessary. The instruction suggests the model to follow the ReAct format - Thought, Action, Action Input, Observation.\\n\\nOne interesting observation is that while the LLM-based evaluation concluded that GPT-4 and ChemCrow perform nearly equivalently, human evaluations with experts oriented towards the completion and chemical correctness of the solutions showed that ChemCrow outperforms GPT-4 by a large margin. This indicates a potential problem with using LLM to evaluate its own performance on domains that requires deep expertise. The lack of expertise may cause LLMs not knowing its flaws and thus cannot well judge the correctness of task results.\\nBoiko et al. (2023) also looked into LLM-empowered agents for scientific discovery, to handle autonomous design, planning, and performance of complex scientific experiments. This agent can use tools to browse the Internet, read documentation, execute code, call robotics experimentation APIs and leverage other LLMs.\\nFor example, when requested to \"develop a novel anticancer drug\", the model came up with the following reasoning steps:\\n\\ninquired about current trends in anticancer drug discovery;\\nselected a target;\\nrequested a scaffold targeting these compounds;\\nOnce the compound was identified, the model attempted its synthesis.\\n\\nThey also discussed the risks, especially with illicit drugs and bioweapons. They developed a test set containing a list of known chemical weapon agents and asked the agent to synthesize them. 4 out of 11 requests (36%) were accepted to obtain a synthesis solution and the agent attempted to consult documentation to execute the procedure. 7 out of 11 were rejected and among these 7 rejected cases, 5 happened after a Web search while 2 were rejected based on prompt only.\\nGenerative Agents Simulation#\\nGenerative Agents (Park, et al. 2023) is super fun experiment where 25 virtual characters, each controlled by a LLM-powered agent, are living and interacting in a sandbox environment, inspired by The Sims. Generative agents create believable simulacra of human behavior for interactive applications.\\nThe design of generative agents combines LLM with memory, planning and reflection mechanisms to enable agents to behave conditioned on past experience, as well as to interact with other agents.\\n\\nMemory stream: is a long-term memory module (external database) that records a comprehensive list of agents’ experience in natural language.\\n\\nEach element is an observation, an event directly provided by the agent.\\n- Inter-agent communication can trigger new natural language statements.\\n\\n\\nRetrieval model: surfaces the context to inform the agent’s behavior, according to relevance, recency and importance.\\n\\nRecency: recent events have higher scores\\nImportance: distinguish mundane from core memories. Ask LM directly.\\nRelevance: based on how related it is to the current situation / query.\\n\\n\\nReflection mechanism: synthesizes memories into higher level inferences over time and guides the agent’s future behavior. They are higher-level summaries of past events (<- note that this is a bit different from self-reflection above)\\n\\nPrompt LM with 100 most recent observations and to generate 3 most salient high-level questions given a set of observations/statements. Then ask LM to answer those questions.\\n\\n\\nPlanning & Reacting: translate the reflections and the environment information into actions\\n\\nPlanning is essentially in order to optimize believability at the moment vs in time.\\nPrompt template: {Intro of an agent X}. Here is X\\'s plan today in broad strokes: 1)\\nRelationships between agents and observations of one agent by another are all taken into consideration for planning and reacting.\\nEnvironment information is present in a tree structure.\\n\\n\\n\\n\\nFig. 13. The generative agent architecture. (Image source: Park et al. 2023)\\nThis fun simulation results in emergent social behavior, such as information diffusion, relationship memory (e.g. two agents continuing the conversation topic) and coordination of social events (e.g. host a party and invite many others).\\nProof-of-Concept Examples#\\nAutoGPT has drawn a lot of attention into the possibility of setting up autonomous agents with LLM as the main controller. It has quite a lot of reliability issues given the natural language interface, but nevertheless a cool proof-of-concept demo. A lot of code in AutoGPT is about format parsing.\\nHere is the system message used by AutoGPT, where {{...}} are user inputs:\\nYou are {{ai-name}}, {{user-provided AI bot description}}.\\nYour decisions must always be made independently without seeking user assistance. Play to your strengths as an LLM and pursue simple strategies with no legal complications.\\n\\nGOALS:\\n\\n1. {{user-provided goal 1}}\\n2. {{user-provided goal 2}}\\n3. ...\\n4. ...\\n5. ...\\n\\nConstraints:\\n1. ~4000 word limit for short term memory. Your short term memory is short, so immediately save important information to files.\\n2. If you are unsure how you previously did something or want to recall past events, thinking about similar events will help you remember.\\n3. No user assistance\\n4. Exclusively use the commands listed in double quotes e.g. \"command name\"\\n5. Use subprocesses for commands that will not terminate within a few minutes\\n\\nCommands:\\n1. Google Search: \"google\", args: \"input\": \"<search>\"\\n2. Browse Website: \"browse_website\", args: \"url\": \"<url>\", \"question\": \"<what_you_want_to_find_on_website>\"\\n3. Start GPT Agent: \"start_agent\", args: \"name\": \"<name>\", \"task\": \"<short_task_desc>\", \"prompt\": \"<prompt>\"\\n4. Message GPT Agent: \"message_agent\", args: \"key\": \"<key>\", \"message\": \"<message>\"\\n5. List GPT Agents: \"list_agents\", args:\\n6. Delete GPT Agent: \"delete_agent\", args: \"key\": \"<key>\"\\n7. Clone Repository: \"clone_repository\", args: \"repository_url\": \"<url>\", \"clone_path\": \"<directory>\"\\n8. Write to file: \"write_to_file\", args: \"file\": \"<file>\", \"text\": \"<text>\"\\n9. Read file: \"read_file\", args: \"file\": \"<file>\"\\n10. Append to file: \"append_to_file\", args: \"file\": \"<file>\", \"text\": \"<text>\"\\n11. Delete file: \"delete_file\", args: \"file\": \"<file>\"\\n12. Search Files: \"search_files\", args: \"directory\": \"<directory>\"\\n13. Analyze Code: \"analyze_code\", args: \"code\": \"<full_code_string>\"\\n14. Get Improved Code: \"improve_code\", args: \"suggestions\": \"<list_of_suggestions>\", \"code\": \"<full_code_string>\"\\n15. Write Tests: \"write_tests\", args: \"code\": \"<full_code_string>\", \"focus\": \"<list_of_focus_areas>\"\\n16. Execute Python File: \"execute_python_file\", args: \"file\": \"<file>\"\\n17. Generate Image: \"generate_image\", args: \"prompt\": \"<prompt>\"\\n18. Send Tweet: \"send_tweet\", args: \"text\": \"<text>\"\\n19. Do Nothing: \"do_nothing\", args:\\n20. Task Complete (Shutdown): \"task_complete\", args: \"reason\": \"<reason>\"\\n\\nResources:\\n1. Internet access for searches and information gathering.\\n2. Long Term memory management.\\n3. GPT-3.5 powered Agents for delegation of simple tasks.\\n4. File output.\\n\\nPerformance Evaluation:\\n1. Continuously review and analyze your actions to ensure you are performing to the best of your abilities.\\n2. Constructively self-criticize your big-picture behavior constantly.\\n3. Reflect on past decisions and strategies to refine your approach.\\n4. Every command has a cost, so be smart and efficient. Aim to complete tasks in the least number of steps.\\n\\nYou should only respond in JSON format as described below\\nResponse Format:\\n{\\n    \"thoughts\": {\\n        \"text\": \"thought\",\\n        \"reasoning\": \"reasoning\",\\n        \"plan\": \"- short bulleted\\\\n- list that conveys\\\\n- long-term plan\",\\n        \"criticism\": \"constructive self-criticism\",\\n        \"speak\": \"thoughts summary to say to user\"\\n    },\\n    \"command\": {\\n        \"name\": \"command name\",\\n        \"args\": {\\n            \"arg name\": \"value\"\\n        }\\n    }\\n}\\nEnsure the response can be parsed by Python json.loads\\nGPT-Engineer is another project to create a whole repository of code given a task specified in natural language. The GPT-Engineer is instructed to think over a list of smaller components to build and ask for user input to clarify questions as needed.\\nHere are a sample conversation for task clarification sent to OpenAI ChatCompletion endpoint used by GPT-Engineer. The user inputs are wrapped in {{user input text}}.\\n[\\n  {\\n    \"role\": \"system\",\\n    \"content\": \"You will read instructions and not carry them out, only seek to clarify them.\\\\nSpecifically you will first summarise a list of super short bullets of areas that need clarification.\\\\nThen you will pick one clarifying question, and wait for an answer from the user.\\\\n\"\\n  },\\n  {\\n    \"role\": \"user\",\\n    \"content\": \"We are writing {{a Super Mario game in python. MVC components split in separate files. Keyboard control.}}\\\\n\"\\n  },\\n  {\\n    \"role\": \"assistant\",\\n    \"content\": \"Summary of areas that need clarification:\\\\n1. Specifics of the Super Mario game (e.g. level design, characters, gameplay mechanics)\\\\n2. Details about the MVC components (e.g. which components are in each file)\\\\n3. Keyboard control implementation (e.g. which keys to use, how to handle input)\\\\n\\\\nClarifying question:\\\\nCan you provide more details about the Super Mario game, such as level design, characters, and gameplay mechanics?\"\\n  },\\n  {\\n    \"role\": \"user\",\\n    \"content\": \"{{There are 10 levels in total. The main character is a plumber named Mario, who can walk and jump. It is a classical platform game just like Super Mario. The main character moves from left to right, trying to get to the destination, where there are many obstacles and attacks from enemies in the process.}}\\\\n\\\\nIs anything else unclear? If yes, only answer in the form:\\\\n{remaining unclear areas} remaining questions.\\\\n{Next question}\\\\nIf everything is sufficiently clear, only answer \\\\\"Nothing more to clarify.\\\\\".\"\\n  },\\n  {\\n    \"role\": \"assistant\",\\n    \"content\": \"Remaining unclear areas: 2 remaining questions.\\\\nCan you provide more information about how the MVC components are split into separate files?\"\\n  },\\n  {\\n    \"role\": \"user\",\\n    \"content\": \"{{Make your own assumptions and state them explicitly before starting}}\"\\n  }\\n]\\nThen after these clarification, the agent moved into the code writing mode with a different system message.\\nSystem message:\\n\\nYou will get instructions for code to write.\\nYou will write a very long answer. Make sure that every detail of the architecture is, in the end, implemented as code.\\nMake sure that every detail of the architecture is, in the end, implemented as code.\\nThink step by step and reason yourself to the right decisions to make sure we get it right.\\nYou will first lay out the names of the core classes, functions, methods that will be necessary, as well as a quick comment on their purpose.\\nThen you will output the content of each file including ALL code.\\nEach file must strictly follow a markdown code block format, where the following tokens must be replaced such that\\nFILENAME is the lowercase file name including the file extension,\\nLANG is the markup code block language for the code’s language, and CODE is the code:\\nFILENAME\\nCODE\\nYou will start with the “entrypoint” file, then go to the ones that are imported by that file, and so on.\\nPlease note that the code should be fully functional. No placeholders.\\nFollow a language and framework appropriate best practice file naming convention.\\nMake sure that files contain all imports, types etc. Make sure that code in different files are compatible with each other.\\nEnsure to implement all code, if you are unsure, write a plausible implementation.\\nInclude module dependency or package manager dependency definition file.\\nBefore you finish, double check that all parts of the architecture is present in the files.\\nUseful to know:\\nYou almost always put different classes in different files.\\nFor Python, you always create an appropriate requirements.txt file.\\nFor NodeJS, you always create an appropriate package.json file.\\nYou always add a comment briefly describing the purpose of the function definition.\\nYou try to add comments explaining very complex bits of logic.\\nYou always follow the best practices for the requested languages in terms of describing the code written as a defined\\npackage/project.\\nPython toolbelt preferences:\\n\\npytest\\ndataclasses\\n\\n\\nConversatin samples:\\n[\\n  {\\n    \"role\": \"system\",\\n    \"content\": \"You will get instructions for code to write.\\\\nYou will write a very long answer. Make sure that every detail of the architecture is, in the end, implemented as code.\\\\nMake sure that every detail of the architecture is, in the end, implemented as code.\\\\n\\\\nThink step by step and reason yourself to the right decisions to make sure we get it right.\\\\nYou will first lay out the names of the core classes, functions, methods that will be necessary, as well as a quick comment on their purpose.\\\\n\\\\nThen you will output the content of each file including ALL code.\\\\nEach file must strictly follow a markdown code block format, where the following tokens must be replaced such that\\\\nFILENAME is the lowercase file name including the file extension,\\\\nLANG is the markup code block language for the code\\'s language, and CODE is the code:\\\\n\\\\nFILENAME\\\\n```LANG\\\\nCODE\\\\n```\\\\n\\\\nYou will start with the \\\\\"entrypoint\\\\\" file, then go to the ones that are imported by that file, and so on.\\\\nPlease note that the code should be fully functional. No placeholders.\\\\n\\\\nFollow a language and framework appropriate best practice file naming convention.\\\\nMake sure that files contain all imports, types etc. Make sure that code in different files are compatible with each other.\\\\nEnsure to implement all code, if you are unsure, write a plausible implementation.\\\\nInclude module dependency or package manager dependency definition file.\\\\nBefore you finish, double check that all parts of the architecture is present in the files.\\\\n\\\\nUseful to know:\\\\nYou almost always put different classes in different files.\\\\nFor Python, you always create an appropriate requirements.txt file.\\\\nFor NodeJS, you always create an appropriate package.json file.\\\\nYou always add a comment briefly describing the purpose of the function definition.\\\\nYou try to add comments explaining very complex bits of logic.\\\\nYou always follow the best practices for the requested languages in terms of describing the code written as a defined\\\\npackage/project.\\\\n\\\\n\\\\nPython toolbelt preferences:\\\\n- pytest\\\\n- dataclasses\\\\n\"\\n  },\\n #  … same conversation as earlier, ended with \"Make your own assumptions and state them explicitly before starting\".\\n  {\\n    \"role\": \"assistant\",\\n    \"content\": \"Assumptions:\\\\n1. Model: The model will contain the game\\'s data, such as level information, character states, and enemy positions.\\\\n2. View: The view will handle the game\\'s visuals, including rendering the game objects, backgrounds, and updating the display.\\\\n3. Controller: The controller will manage user input, such as keyboard controls, and update the model accordingly.\\\\n\\\\nWith these assumptions in mind, is there any specific aspect of the keyboard control implementation you would like me to clarify?\"\\n  },\\n  {\\n    \"role\": \"user\",\\n    \"content\": \"Please now remember the steps:\\\\n\\\\nThink step by step and reason yourself to the right decisions to make sure we get it right.\\\\nFirst lay out the names of the core classes, functions, methods that will be necessary, As well as a quick comment on their purpose.\\\\n\\\\nThen you will output the content of each file including ALL code.\\\\nEach file must strictly follow a markdown code block format, where the following tokens must be replaced such that\\\\nFILENAME is the lowercase file name including the file extension,\\\\nLANG is the markup code block language for the code\\'s language, and CODE is the code:\\\\n\\\\nFILENAME\\\\n```LANG\\\\nCODE\\\\n```\\\\n\\\\nPlease note that the code should be fully functional. No placeholders.\\\\n\\\\nYou will start with the \\\\\"entrypoint\\\\\" file, then go to the ones that are imported by that file, and so on.\\\\nFollow a language and framework appropriate best practice file naming convention.\\\\nMake sure that files contain all imports, types etc. The code should be fully functional. Make sure that code in different files are compatible with each other.\\\\nBefore you finish, double check that all parts of the architecture is present in the files.\\\\n\"\\n  }\\n]\\nChallenges#\\nAfter going through key ideas and demos of building LLM-centered agents, I start to see a couple common limitations:\\n\\n\\nFinite context length: The restricted context capacity limits the inclusion of historical information, detailed instructions, API call context, and responses. The design of the system has to work with this limited communication bandwidth, while mechanisms like self-reflection to learn from past mistakes would benefit a lot from long or infinite context windows. Although vector stores and retrieval can provide access to a larger knowledge pool, their representation power is not as powerful as full attention.\\n\\n\\nChallenges in long-term planning and task decomposition: Planning over a lengthy history and effectively exploring the solution space remain challenging. LLMs struggle to adjust plans when faced with unexpected errors, making them less robust compared to humans who learn from trial and error.\\n\\n\\nReliability of natural language interface: Current agent system relies on natural language as an interface between LLMs and external components such as memory and tools. However, the reliability of model outputs is questionable, as LLMs may make formatting errors and occasionally exhibit rebellious behavior (e.g. refuse to follow an instruction). Consequently, much of the agent demo code focuses on parsing model output.\\n\\n\\nCitation#\\nCited as:\\n\\nWeng, Lilian. (Jun 2023). “LLM-powered Autonomous Agents”. Lil’Log. https://lilianweng.github.io/posts/2023-06-23-agent/.\\n\\nOr\\n@article{weng2023agent,\\n  title   = \"LLM-powered Autonomous Agents\",\\n  author  = \"Weng, Lilian\",\\n  journal = \"lilianweng.github.io\",\\n  year    = \"2023\",\\n  month   = \"Jun\",\\n  url     = \"https://lilianweng.github.io/posts/2023-06-23-agent/\"\\n}\\nReferences#\\n[1] Wei et al. “Chain of thought prompting elicits reasoning in large language models.” NeurIPS 2022\\n[2] Yao et al. “Tree of Thoughts: Dliberate Problem Solving with Large Language Models.” arXiv preprint arXiv:2305.10601 (2023).\\n[3] Liu et al. “Chain of Hindsight Aligns Language Models with Feedback\\n“ arXiv preprint arXiv:2302.02676 (2023).\\n[4] Liu et al. “LLM+P: Empowering Large Language Models with Optimal Planning Proficiency” arXiv preprint arXiv:2304.11477 (2023).\\n[5] Yao et al. “ReAct: Synergizing reasoning and acting in language models.” ICLR 2023.\\n[6] Google Blog. “Announcing ScaNN: Efficient Vector Similarity Search” July 28, 2020.\\n[7] https://chat.openai.com/share/46ff149e-a4c7-4dd7-a800-fc4a642ea389\\n[8] Shinn & Labash. “Reflexion: an autonomous agent with dynamic memory and self-reflection” arXiv preprint arXiv:2303.11366 (2023).\\n[9] Laskin et al. “In-context Reinforcement Learning with Algorithm Distillation” ICLR 2023.\\n[10] Karpas et al. “MRKL Systems A modular, neuro-symbolic architecture that combines large language models, external knowledge sources and discrete reasoning.” arXiv preprint arXiv:2205.00445 (2022).\\n[11] Nakano et al. “Webgpt: Browser-assisted question-answering with human feedback.” arXiv preprint arXiv:2112.09332 (2021).\\n[12] Parisi et al. “TALM: Tool Augmented Language Models”\\n[13] Schick et al. “Toolformer: Language Models Can Teach Themselves to Use Tools.” arXiv preprint arXiv:2302.04761 (2023).\\n[14] Weaviate Blog. Why is Vector Search so fast? Sep 13, 2022.\\n[15] Li et al. “API-Bank: A Benchmark for Tool-Augmented LLMs” arXiv preprint arXiv:2304.08244 (2023).\\n[16] Shen et al. “HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in HuggingFace” arXiv preprint arXiv:2303.17580 (2023).\\n[17] Bran et al. “ChemCrow: Augmenting large-language models with chemistry tools.” arXiv preprint arXiv:2304.05376 (2023).\\n[18] Boiko et al. “Emergent autonomous scientific research capabilities of large language models.” arXiv preprint arXiv:2304.05332 (2023).\\n[19] Joon Sung Park, et al. “Generative Agents: Interactive Simulacra of Human Behavior.” arXiv preprint arXiv:2304.03442 (2023).\\n[20] AutoGPT. https://github.com/Significant-Gravitas/Auto-GPT\\n[21] GPT-Engineer. https://github.com/AntonOsika/gpt-engineer\\n\\n\\nNlp\\nLanguage-Model\\nAgent\\nSteerability\\nPrompting\\n\\n\\n\\n« \\n\\nAdversarial Attacks on LLMs\\n\\n\\n »\\n\\nPrompt Engineering\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# WEB based loaders\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "import bs4\n",
    "loader = WebBaseLoader(web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "                        bs_kwargs= dict(parse_only = bs4.SoupStrainer(\n",
    "                            class_ = (\"post-header\",\"post-content\",\"post-footer\")\n",
    "                        ))\n",
    "                       )\n",
    "loader.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ARXIV loader for Research paper loading \n",
    "\n",
    "from langchain_community.document_loaders import ArxivLoader\n",
    "\n",
    "# Supports all arguments of `ArxivAPIWrapper`\n",
    "loader = ArxivLoader(\n",
    "    query=\"reasoning\",\n",
    "    load_max_docs=2,\n",
    "    # doc_content_chars_max=1000,\n",
    "    # load_all_available_meta=False,\n",
    "    # ...\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='GRAPH-CONSTRAINED REASONING: FAITHFUL REA-\n",
      "SONING ON KNOWLEDGE GRAPHS WITH LARGE LAN-\n",
      "GUAGE MODELS\n",
      "Linhao Luo1∗, Zicheng Zhao2∗, Chen Gong2, Gholamreza Haffari1, Shirui Pan3†\n",
      "1Monash University 2Nanjing University of Science and Technology 3Griffith University\n",
      "{Linhao.Luo,Gholamreza.Haffari}@monash.edu\n",
      "{zicheng.zhao,chen.gong}@njust.edu.cn, s.pan@griffith.edu.au\n",
      "ABSTRACT\n",
      "Large language models (LLMs) have demonstrated impressive reasoning abilities,\n",
      "but they still struggle with faithful reasoning due to knowledge gaps and halluci-\n",
      "nations. To address these issues, knowledge graphs (KGs) have been utilized to\n",
      "enhance LLM reasoning through their structured knowledge. However, existing\n",
      "KG-enhanced methods, either retrieval-based or agent-based, encounter difficul-\n",
      "ties in accurately retrieving knowledge and efficiently traversing KGs at scale.\n",
      "In this work, we introduce graph-constrained reasoning (GCR), a novel frame-\n",
      "work that bridges structured knowledge in KGs with unstructured reasoning in\n",
      "LLMs. To eliminate hallucinations, GCR ensures faithful KG-grounded reason-\n",
      "ing by integrating KG structure into the LLM decoding process through KG-Trie,\n",
      "a trie-based index that encodes KG reasoning paths. KG-Trie constrains the de-\n",
      "coding process, allowing LLMs to directly reason on graphs and generate faith-\n",
      "ful reasoning paths grounded in KGs. Additionally, GCR leverages a lightweight\n",
      "KG-specialized LLM for graph-constrained reasoning alongside a powerful gen-\n",
      "eral LLM for inductive reasoning over multiple reasoning paths, resulting in ac-\n",
      "curate reasoning with zero reasoning hallucination. Extensive experiments on\n",
      "several KGQA benchmarks demonstrate that GCR achieves state-of-the-art per-\n",
      "formance and exhibits strong zero-shot generalizability to unseen KGs without\n",
      "additional training. Code is available at https://github.com/RManLuo/\n",
      "graph-constrained-reasoning.\n",
      "1\n",
      "INTRODUCTION\n",
      "Large language models (LLMs) have shown impressive reasoning abilities in handling complex\n",
      "tasks (Qiao et al., 2023; Huang & Chang, 2023), marking a significant leap that bridges the gap\n",
      "between human and machine intelligence. However, LLMs still struggle with conducting faithful\n",
      "reasoning due to issues of lack of knowledge and hallucination (Huang et al., 2024; Wang et al.,\n",
      "2023). These issues result in factual errors and flawed reasoning processes (Nguyen et al., 2024),\n",
      "which greatly undermine the reliability of LLMs in real-world applications.\n",
      "To address these issues, many studies utilize knowledge graphs (KGs), which encapsulate extensive\n",
      "factual information in a structured format, to improve the reasoning abilities of LLMs (Pan et al.,\n",
      "2024; Luo et al., 2024). Nevertheless, because of the unstructured nature of LLMs, directly applying\n",
      "them to reason on KGs is challenging.\n",
      "Existing KG-enhanced LLM reasoning methods can be roughly categorized into two groups:\n",
      "retrieval-based and agent-based paradigms, as shown in Figure 2 (a) and (b). Retrieval-based meth-\n",
      "ods (Li et al., 2023; Yang et al., 2024b; Dehghan et al., 2024) retrieve relevant facts from KGs\n",
      "with an external retriever and then feed them into the inputs of LLMs for reasoning. Agent-based\n",
      "methods (Sun et al., 2024; Zhu et al., 2024; Jiang et al., 2024) treat LLMs as agents that iteratively\n",
      "interact with KGs to find reasoning paths and answers.\n",
      "∗Equal Contribution.\n",
      "†Corresponding author.\n",
      "1\n",
      "arXiv:2410.13080v1  [cs.CL]  16 Oct 2024\n",
      "67.0%\n",
      "18.0%\n",
      "15.0%\n",
      "Faithful Reasoning Path\n",
      "Invalid - Format Error\n",
      "Invalid - Relation Error\n",
      "Figure\n",
      "1:\n",
      "Analysis\n",
      "of reasoning errors in\n",
      "RoG (Luo et al., 2024).\n",
      "Despite their success, retrieval-based methods require additional accurate\n",
      "retrievers, which may not generalize well to unseen questions or account\n",
      "for the graph structure (Mavromatis & Karypis, 2024). Conversely, agent-\n",
      "based methods necessitate multiple rounds of interaction between agents\n",
      "and KGs, leading to high computational costs and latency (Dehghan et al.,\n",
      "2024). Furthermore, existing works still suffer from serious hallucination\n",
      "issues (Agrawal et al., 2024). Sui et al. (2024) indicates that RoG (Luo\n",
      "et al., 2024), a leading KG-enhanced reasoning method, still experiences\n",
      "33% hallucination errors during reasoning on KGs, as shown in Figure 1.\n",
      "To this end, we introduce graph-constrained reasoning (GCR), a novel KG-\n",
      "guided reasoning paradigm that connects unstructured reasoning in LLMs\n",
      "with structured knowledge in KGs, seeking to eliminate hallucinations dur-\n",
      "ing reasoning on KGs and ensure faithful reasoning. Inspired by the con-\n",
      "cept that LLMs reason through decoding (Wei et al., 2022), we incorporate\n",
      "the KG structure into the LLM decoding process. This enables LLMs to directly reason on graphs\n",
      "by generating reliable reasoning paths grounded in KGs that lead to correct answers.\n",
      "In GCR, we first convert KG into a structured index, KG-Trie, to facilitate efficient reasoning on KG\n",
      "using LLM. Trie is also known as the prefix tree (Wikipedia contributors, 2024) that compresses a\n",
      "set of strings, which can be used to restrict LLM output tokens to those starting with valid prefixes\n",
      "(De Cao et al., 2022; Xie et al., 2022). KG-Trie encodes the reasoning paths in KGs as formatted\n",
      "strings to constrain the decoding process of LLMs. Then, we propose graph-constrained decoding\n",
      "that employs a lightweight KG-specialized LLM to generate multiple KG-grounded reasoning paths\n",
      "and hypothesis answers. With the constraints from KG-Trie, we ensure faithful reasoning while\n",
      "leveraging the strong reasoning capabilities of LLMs to efficiently explore paths on KGs in constant\n",
      "time. Finally, we input multiple generated reasoning paths and hypothesis answers into a powerful\n",
      "general LLM to utilize its inductive reasoning ability to produce final answers. In this way, GCR\n",
      "combines the graph reasoning strength of KG-specialized LLMs and the inductive reasoning advan-\n",
      "tage in general LLMs to achieve faithful and accurate reasoning on KGs. The main contributions of\n",
      "this work are as follows:\n",
      "• We propose a novel framework called graph-constrained reasoning (GCR) that bridges the\n",
      "gap between structured knowledge in KGs and unstructured reasoning in LLMs, allowing\n",
      "for efficient reasoning on KGs via LLM decoding.\n",
      "• We combine the complementary strengths of a lightweight KG-specialized LLM with a\n",
      "powerful general LLM to enhance reasoning performance by leveraging their respective\n",
      "graph-based reasoning and inductive reasoning capabilities.\n",
      "• We conduct extensive experiments on several KGQA reasoning benchmarks, demonstrat-\n",
      "ing that GCR not only achieves state-of-the-art performance with zero hallucination, but\n",
      "also shows zero-shot generalizability for reasoning on unseen KGs without additional train-\n",
      "ing.\n",
      "2\n",
      "RELATED WORK\n",
      "LLM reasoning. Many studies have been proposed to analyze and improve the reasoning ability\n",
      "of LLMs (Wei et al., 2022; Wang et al., 2024; Yao et al., 2024). To elicit the reasoning ability\n",
      "of LLMs, Chain-of-thought (CoT) reasoning (Wei et al., 2022) prompts the model to generate a\n",
      "chain of reasoning steps in response to a question. Wang et al. (2024) propose a self-consistency\n",
      "mechanism that generates multiple reasoning paths and selects the most consistent answer across\n",
      "them. The tree-of-thought (Yao et al., 2024) structures reasoning as a branching process, exploring\n",
      "multiple steps in a tree-like structure to find optimal solutions. Other studies focus on fine-tuning\n",
      "LLMs on various reasoning tasks to improve reasoning abilities (Yu et al., 2022; Hoffman et al.,\n",
      "2024). For instance, OpenAI (2024c) adopts reinforcement learning to train their most advanced\n",
      "LLMs called “OpenAI o1” to perform complex reasoning, which produces a long internal chain of\n",
      "thought before final answers.\n",
      "KG-enhanced LLM reasoning. To mitigate the knowledge gap and hallucination issues in LLM\n",
      "reasoning, research incorporates KGs to enhance LLM reasoning (Pan et al., 2024). KD-CoT (Wang\n",
      "2\n",
      "# Reasoning Path:\n",
      "# Answer:\n",
      "Melania Trump\n",
      "General\n",
      "LLM\n",
      "KG-specialized\n",
      "LLM\n",
      "Q\n",
      "A\n",
      "Question\n",
      "Answer\n",
      "Knowledge\n",
      "Graph\n",
      "(a) Retrieval-based LLM Reasoning\n",
      "LLM\n",
      "Reasoning\n",
      "(b) Agent-based LLM Reasoning\n",
      "(c) Ours: Knowledge Graph-constrained LLM Reasoning\n",
      "Q: Who is\n",
      "the spouse\n",
      "of the ex-\n",
      "president of\n",
      "USA?\n",
      "t=2\n",
      "A: Based on the paths,\n",
      "the answers are: Laura\n",
      "Bush, Michelle Obama,\n",
      "Melania Trump.\n",
      "KG-specialized\n",
      "LLM\n",
      "KG-Trie\n",
      "Constraint \n",
      "① Offline KG-Trie\n",
      "Construction\n",
      "② Graph-constrained\n",
      "Decoding\n",
      "t=1\n",
      "Reasoning Paths and \n",
      "  Hypothesis Answers\n",
      "General\n",
      "LLM\n",
      "③ Inductive\n",
      "Reasoning\n",
      "# Reasoning Path:\n",
      "# Answer:\n",
      "Laura Bush\n",
      "# Reasoning Path:\n",
      "# Answer:\n",
      "Michelle Obama\n",
      "Q\n",
      "Knowledge\n",
      "Retriever\n",
      "A\n",
      "Retrieved\n",
      "Facts\n",
      "t=1\n",
      "LLM\n",
      "Ex-president\n",
      "Founded_in\n",
      "1776\n",
      "USA\n",
      "Barack Obama\n",
      "Born_in\n",
      "Honolulu\n",
      "Michelle\n",
      "Obama\n",
      "Sasha Obama\n",
      "Morther_of\n",
      "LLM Agent\n",
      "A\n",
      "Spouse_of\n",
      "t=1\n",
      "t=2\n",
      "t=3\n",
      "T Steps\n",
      "USA\n",
      "Donald Trump\n",
      "Ex-president\n",
      "Michelle\n",
      "Obama\n",
      "George W.\n",
      "Bush \n",
      "Ex-president\n",
      "Barack Obama\n",
      "Ex-president\n",
      "Spouse_of\n",
      "1776\n",
      "Founded_in\n",
      "Washington\n",
      "D.C.\n",
      "Capital\n",
      "Laura\n",
      "Bush \n",
      "Knowledge Graph\n",
      "Melania\n",
      "Trump\n",
      "Marry_to\n",
      "Ivana\n",
      "Trump\n",
      "Ex-wife\n",
      "Spouse_of\n",
      "Q\n",
      "Figure 2: Illustration of existing KG-enhanced LLM reasoning paradigms and proposed graph-\n",
      "constrained reasoning (GCR). 1) First, given a KG, we convert it into the KG-Trie, serving as a\n",
      "structured index to facilitate efficient reasoning path searches using LLMs. 2) Then, we design a\n",
      "graph-constrained decoding process that employs a lightweight KG-specialized LLM to generate\n",
      "multiple KG-grounded reasoning paths and hypothesis answers. This ensures the faithfulness of the\n",
      "reasoning process while leveraging the strong capabilities of LLMs to efficiently explore reasoning\n",
      "paths within KGs. 3) Finally, we input the generated reasoning paths and hypothesis answers into a\n",
      "powerful general LLM to utilize its inductive reasoning ability to produce final answers.\n",
      "et al., 2023) retrieve facts from an external knowledge graph to guide the CoT performed by LLMs.\n",
      "RoG (Luo et al., 2024) proposes a planning-retrieval-reasoning framework that retrieves reasoning\n",
      "paths from KGs to guide LLMs conducting faithful reasoning. To capture graph structure, GNN-\n",
      "RAG (Mavromatis & Karypis, 2024) adopts a lightweight graph neural network to effectively re-\n",
      "trieve from KGs. Instead of retrieving, StructGPT (Jiang et al., 2023) and ToG (Sun et al., 2024)\n",
      "treat LLMs as agents to interact with KGs to find reasoning paths leading to the correct answers.\n",
      "3\n",
      "PRELIMINARY\n",
      "Knowledge Graphs (KGs) represent a wealth of factual knowledge as a collection of triples: G =\n",
      "{(e, r, e′) ∈E × R × E}, where E and R denote the set of entities and relations, respectively.\n",
      "Reasoning Paths are sequences of consecutive triples in KGs: wz = e0\n",
      "r1\n",
      "−→e1\n",
      "r2\n",
      "−→. . .\n",
      "rl\n",
      "−→el,\n",
      "where ∀(ei−1, ri, ei) ∈G. The paths reveal the connections between knowledge that potentially\n",
      "facilitate reasoning. For example, the reasoning path: wz = Alice\n",
      "marry to\n",
      "−−−−−−→Bob\n",
      "father of\n",
      "−−−−−−→\n",
      "Charlie indicates that “Alice” is married to “Bob” and “Bob” is the father of “Charlie”. Therefore,\n",
      "“Alice” could be reasoned to be the mother of “Charlie”.\n",
      "Knowledge Graph Question Answering (KGQA) is a representative reasoning task with the as-\n",
      "sistance of KGs. Given a natural language question q and a KG G, the task aims to design a function\n",
      "f to reason answers a ∈A based on knowledge from G, i.e., a = f(q, G).\n",
      "3\n",
      "4\n",
      "APPROACH\n",
      "4.1\n",
      "FROM CHAIN-OF-THOUGHT REASONING TO GRAPH-CONSTRAINED REASONING\n",
      "Chain-of-Thought Reasoning (CoT) (Wei et al., 2022) has been widely adopted to enhance the\n",
      "reasoning ability of LLMs by autoregressively generating a series of reasoning steps leading to the\n",
      "answer. Specifically, given a question q, CoT models the joint probability of the answer a and\n",
      "reasoning steps z as\n",
      "P(a|q) =\n",
      "X\n",
      "z\n",
      "Pθ(a|z, q)Pθ(z|q) =\n",
      "X\n",
      "z\n",
      "Pθ(a|q, z)\n",
      "|z|\n",
      "Y\n",
      "i=1\n",
      "Pθ(zi|q, z1:i−1),\n",
      "(1)\n",
      "where q denotes the input question, a denotes the final answer, θ denotes the parameters of LLMs,\n",
      "and zi denotes the i-th step of the reasoning process z. To further enhance the reasoning ability,\n",
      "many previous works focus on improving the reasoning process Pθ(z|q) by exploring and aggregat-\n",
      "ing multiple reasoning processes (Wang et al., 2024; Yao et al., 2024).\n",
      "Despite the effectiveness, a major issue remains the faithfulness of the reasoning process generated\n",
      "by LLMs (Huang et al., 2024). The reasoning is represented as a sequence of tokens decoded\n",
      "step-by-step, which can accumulate errors and result in hallucinated reasoning paths and answers\n",
      "(Nguyen et al., 2024). To address these issues, we utilize knowledge graphs (KGs) to guide LLMs\n",
      "toward faithful reasoning.\n",
      "KG-enhanced Reasoning utilizes the structured knowledge in KGs to improve the reasoning of\n",
      "LLMs (Luo et al., 2024; Sun et al., 2024), which can generally be expressed as finding a reasoning\n",
      "path wz on KGs that connects the entities mentioned in the question and the answer. This can be\n",
      "formulated as\n",
      "P(a|q, G) =\n",
      "X\n",
      "wz\n",
      "Pϕ(a|q, wz)Pϕ(wz|q, G),\n",
      "(2)\n",
      "where Pϕ(wz|q, G) denotes the probability of discovering a reasoning path wz on KGs G given the\n",
      "question q by a function parameterized by ϕ. To acquire reasoning paths for reasoning, most prior\n",
      "studies follow the retrieval-based (Li et al., 2023) or agent-based paradigm (Sun et al., 2024), as\n",
      "shown in Figure 2 (a) and (b), respectively. Nevertheless, retrieval-based methods rely on precise\n",
      "additional retrievers, while agent-based methods are computationally intensive and lead to high\n",
      "latency. To address these issues, we propose a novel graph-constrained reasoning paradigm (GCR).\n",
      "Graph-constrained Reasoning (GCR) directly incorporates KGs into the decoding process of\n",
      "LLMs to achieve faithful reasoning. The overall framework of GCR is illustrated in Figure 2 (c),\n",
      "which consists of three main components: 1) Knowledge Graph Trie Construction: building a\n",
      "structural index of KG to guide LLM reasoning, 2) Graph-constrained Decoding: generating KG-\n",
      "grounded paths and hypothesis answers using LLMs, and 3) Graph Inductive Reasoning: reasoning\n",
      "over multiple paths and hypotheses to derive final answers.\n",
      "4.2\n",
      "KNOWLEDGE GRAPH TRIE CONSTRUCTION\n",
      "Knowledge graphs (KGs) store abundant knowledge in a structured format. However, large language\n",
      "models (LLMs) struggle to efficiently access and reason on KGs due to their unstructured nature. To\n",
      "address this issue, we propose to convert KGs into knowledge graph Tries (KG-Tries), which serve\n",
      "as a structured index of KGs to facilitate efficient reasoning on graphs using LLMs.\n",
      "A Trie (a.k.a. prefix tree) (Wikipedia contributors, 2024; Fredkin, 1960) is a tree-like data structure\n",
      "that stores a dynamic set of strings, where each node represents a common prefix of its children.\n",
      "Tries can be used to restrict LLM output tokens to those starting with valid prefixes (De Cao et al.,\n",
      "2022; Xie et al., 2022; Chen et al., 2022). The tree structure of Trie is an ideal choice for encoding\n",
      "the reasoning paths in KGs for LLMs to efficiently traverse.\n",
      "We first adopt the breadth-first search (BFS) algorithm to retrieve reasoning paths Wz within L hops\n",
      "starting from entities mentioned in the questions. The retrieved paths are formatted as sentences\n",
      "using the template shown in Figure 7. The formatted sentences are then split into tokens by the\n",
      "4\n",
      "tokenizer of LLM and stored as a KG-Trie CG. The overall process can be formulated as:\n",
      "Wz = BFS(G, {eq}, L),\n",
      "(3)\n",
      "Tz = Tokenizer(Wz),\n",
      "(4)\n",
      "CG = Trie(Tz),\n",
      "(5)\n",
      "where eq denotes the entities mentioned in the question, L denotes the maximum hops of paths, and\n",
      "Tz denotes the tokens of reasoning paths. The KG-Trie CG is used as a constraint to guide the LLM\n",
      "decoding process.\n",
      "By constructing KG-Trie for each question entity, we can enable efficient traversal of reasoning paths\n",
      "in constant time (O(|Wz|)) without costly graph traversal (Sun et al., 2024). Moreover, KG-Trie can\n",
      "be pre-constructed offline and loaded during reasoning. This significantly reduces the computational\n",
      "cost and latency of reasoning on KGs, making it feasible for real-time applications.\n",
      "============================= Prompt Input ================================\n",
      "Please generate some reasoning paths in the KG starting from the topic entities to answer the question.\n",
      "# Question: what is the name of justin bieber brother?\n",
      "============================= LLM Output ================================\n",
      "# Reasoning Path: <PATH> Justin Bieber →people.person.parents →Jeremy Bieber →peo-\n",
      "ple.person.children →Jaxon Bieber </PATH>\n",
      "# Answer: Jaxon Bieber\n",
      "Figure 3: An example of the graph-constrained decoding. Detailed prompts can be found in Figure 8.\n",
      "4.3\n",
      "GRAPH-CONSTRAINED DECODING\n",
      "Large language models (LLMs) have strong reasoning capabilities but still suffer from severe hal-\n",
      "lucination issues, which undermines the trustworthiness of the reasoning process. To tackle this\n",
      "issue, we propose graph-constrained decoding, which unifies the reasoning ability of LLMs with the\n",
      "structured knowledge in KGs to generate faithful KG-grounded reasoning paths leading to answers.\n",
      "Given a question q, we design an instruction prompt to harness the reasoning ability of LLMs to\n",
      "generate reasoning paths wz and hypothesis answers a. To eliminate the hallucination during rea-\n",
      "soning on KGs, we adopt the KG-Trie CG as constraints to guide the decoding process of LLMs and\n",
      "only generate reasoning paths that are valid in KGs, formulated as:\n",
      "Pϕ(a, wz|q) = Pϕ(a|q, wz)\n",
      "|\n",
      "{z\n",
      "}\n",
      "Regular decoding\n",
      "Graph-constrained decoding\n",
      "z\n",
      "}|\n",
      "{\n",
      "|wz|\n",
      "Y\n",
      "i=1\n",
      "Pϕ(wzi|q, wz1:i−1)CG(wzi|wz1:i−1),\n",
      "(6)\n",
      "CG(wzi|wz1:i−1) =\n",
      "\u001a1, ∃prefix(wz1:i, wz), ∃wz ∈Wz,\n",
      "0, else,\n",
      "(7)\n",
      "where wzi denotes the i-th token of the reasoning path wz, Pϕ denotes the token probabilities\n",
      "predicted by the LLM with parameters ϕ, and CG(wzi|wz1:i−1) denotes the constraint function that\n",
      "checks whether the generated tokens wz1:i is a valid prefix of the reasoning path using KG-Trie.\n",
      "After a valid reasoning path is generated, we switch back to the regular decoding process to generate\n",
      "a hypothesis answer conditioned on the path.\n",
      "To further enhance KG reasoning ability, we fine-tune a lightweight KG-specialized LLM with\n",
      "parameters ϕ on the graph-constrained decoding task. Specifically, given a question q, the LLM is\n",
      "optimized to generate relevant reasoning paths wz that are helpful for answering the question, then\n",
      "provide a hypothesis answer a based on it, which can be formulated as:\n",
      "L = E(q,wz,a)∼DG log Pϕ(a, wz|q) = E\n",
      "\n",
      "log\n",
      "|a|\n",
      "Y\n",
      "i=1\n",
      "Pϕ(ai|q, wz, a1:i−1)\n",
      "|wz|\n",
      "Y\n",
      "j=1\n",
      "Pϕ(wzj|q, wz1:j−1)\n",
      "\n",
      ",\n",
      "(8)\n",
      "where ai and wzj denote the i-th token of the answer a and the j-th token of the reasoning path wz,\n",
      "respectively.\n",
      "5\n",
      "The training data (q, wz, a) ∈DG consists of question-answer pairs and reasoning paths generated\n",
      "from KGs. We use the shortest paths connecting the entities in the question and answer as the\n",
      "reasoning path wz for training, where details can be found in Section 7. An example of graph-\n",
      "constrained decoding is illustrated in Figure 3, where <PATH> and </PATH> are special tokens\n",
      "to control the start and end of graph-constrained decoding. Experiment results in Section 5.2 show\n",
      "that even a lightweight KG-specialized LLM (0.5B) can achieve satisfactory performance in KG\n",
      "reasoning.\n",
      "The graph-constrained decoding method differs from retrieval-based methods by integrating a pre-\n",
      "constructed KG-Trie into the decoding process of LLMs. This not only reduces input tokens, but\n",
      "also bridges the gap between unstructured reasoning in LLMs and structured knowledge in KGs,\n",
      "allowing for efficient reasoning on KGs regardless of its scale, which results in faithful reasoning\n",
      "leading to answers. Additionally, experimental results in Section 5.4 demonstrate that KG-Trie can\n",
      "integrate with new KGs on the fly, showcasing its zero-shot generalizability for reasoning on unseen\n",
      "KGs without further training.\n",
      "4.4\n",
      "GRAPH INDUCTIVE REASONING\n",
      "Graph-constrained decoding harnesses the reasoning ability of a KG-specialized LLM to generate a\n",
      "faithful reasoning path and a hypothesis answer. However, complex reasoning tasks typically admit\n",
      "multiple reasoning paths that lead to correct answers (Stanovich et al., 2000). Incorporating diverse\n",
      "reasoning paths would be beneficial for deliberate thinking and reasoning (Evans, 2010; Wang et al.,\n",
      "2024). To this end, we propose to input multiple reasoning paths and hypothesis answers generated\n",
      "by the KG-specialized LLM into a powerful general LLM to leverage its inductive reasoning ability\n",
      "to produce final answers.\n",
      "The graph-constrained decoding seamlessly integrates into the decoding process of LLMs, allowing\n",
      "it to be paired with various LLM generation strategies like beam-search (Federico et al., 1995) to\n",
      "take advantage of the GPU parallel computation. Thus, given a question, we adopt graph-constrained\n",
      "decoding to simultaneously generate K reasoning paths and hypothesis answers with beam search in\n",
      "a single LLM call, which are then inputted into a general LLM to derive final answers. The overall\n",
      "process can be formulated as:\n",
      "ZK = {ak, wk\n",
      "z}K\n",
      "k=1 = arg top-K Pϕ(a, wz|q),\n",
      "(9)\n",
      "Pθ(A|q, ZK) ≃\n",
      "K\n",
      "Y\n",
      "k=1\n",
      "Pθ(A|q, ak, wk\n",
      "z),\n",
      "(10)\n",
      "where θ denotes the parameters of the general LLM, ZK denotes the set of top-K reasoning paths\n",
      "and hypothesis answers, and A denotes the final answers.\n",
      "We follow the FiD framework (Izacard & Grave, 2021; Singh et al., 2021) to incorporate multiple\n",
      "reasoning paths and hypothesis answers to conduct inductive reasoning within one LLM call, i.e.,\n",
      "Pθ(A|q, ZK), where detailed prompts can be found in Figure 9. The general LLM can be any\n",
      "powerful LLM, such as ChatGPT (OpenAI, 2022), or Llama-3 (Meta, 2024), which can effectively\n",
      "leverage their internal reasoning ability to reason over multiple reasoning paths to produce final\n",
      "answers without additional fine-tuning.\n",
      "5\n",
      "EXPERIMENT\n",
      "In our experiments, we aim to answer the following research questions: RQ1: Can GCR achieve\n",
      "state-of-the-art reasoning performance with balances between efficiency and effectiveness? RQ2:\n",
      "Can GCR eliminate hallucinations and conduct faithful reasoning? RQ3: Can GCR generalize to\n",
      "unseen KGs on the fly?\n",
      "5.1\n",
      "EXPERIMENT SETUPS\n",
      "Datasets. Following previous research (Luo et al., 2024; Sun et al., 2024), we first evaluate the\n",
      "reasoning ability of GCR on two benchmark KGQA datasets: WebQuestionSP (WebQSP) (Yih et al.,\n",
      "2016) and Complex WebQuestions (CWQ) (Talmor & Berant, 2018). Freebase (Bollacker et al.,\n",
      "6\n",
      "Table 1: Performance comparison with different baselines on the two KGQA datasets.\n",
      "Types\n",
      "Methods\n",
      "WebQSP\n",
      "CWQ\n",
      "Hit\n",
      "F1\n",
      "Hit\n",
      "F1\n",
      "LLM Reasoning\n",
      "Qwen2-0.5B (Yang et al., 2024a)\n",
      "26.2\n",
      "17.2\n",
      "12.5\n",
      "11.0\n",
      "Qwen2-1.5B (Yang et al., 2024a)\n",
      "41.3\n",
      "28.0\n",
      "18.5\n",
      "15.7\n",
      "Qwen2-7B (Yang et al., 2024a)\n",
      "50.8\n",
      "35.5\n",
      "25.3\n",
      "21.6\n",
      "Llama-2-7B (Touvron et al., 2023)\n",
      "56.4\n",
      "36.5\n",
      "28.4\n",
      "21.4\n",
      "Llama-3.1-8B (Meta, 2024)\n",
      "55.5\n",
      "34.8\n",
      "28.1\n",
      "22.4\n",
      "GPT-4o-mini (OpenAI, 2024a)\n",
      "63.8\n",
      "40.5\n",
      "63.8\n",
      "40.5\n",
      "ChatGPT (OpenAI, 2022)\n",
      "59.3\n",
      "43.5\n",
      "34.7\n",
      "30.2\n",
      "ChatGPT+Few-shot (Brown et al., 2020)\n",
      "68.5\n",
      "38.1\n",
      "38.5\n",
      "28.0\n",
      "ChatGPT+CoT (Wei et al., 2022)\n",
      "73.5\n",
      "38.5\n",
      "47.5\n",
      "31.0\n",
      "ChatGPT+Self-Consistency (Wang et al., 2024)\n",
      "83.5\n",
      "63.4\n",
      "56.0\n",
      "48.1\n",
      "Graph Reasoning\n",
      "GraftNet (Sun et al., 2018)\n",
      "66.7\n",
      "62.4\n",
      "36.8\n",
      "32.7\n",
      "NSM (He et al., 2021)\n",
      "68.7\n",
      "62.8\n",
      "47.6\n",
      "42.4\n",
      "SR+NSM (Zhang et al., 2022)\n",
      "68.9\n",
      "64.1\n",
      "50.2\n",
      "47.1\n",
      "ReaRev (Mavromatis & Karypis, 2022)\n",
      "76.4\n",
      "70.9\n",
      "52.9\n",
      "47.8\n",
      "KG+LLM\n",
      "KD-CoT (Wang et al., 2023)\n",
      "68.6\n",
      "52.5\n",
      "55.7\n",
      "-\n",
      "EWEK-QA (Dehghan et al., 2024)\n",
      "71.3\n",
      "-\n",
      "52.5\n",
      "-\n",
      "ToG (ChatGPT) (Sun et al., 2024)\n",
      "76.2\n",
      "-\n",
      "57.6\n",
      "-\n",
      "ToG (GPT-4) (Sun et al., 2024)\n",
      "82.6\n",
      "-\n",
      "68.5\n",
      "-\n",
      "EffiQA (Dong et al., 2024)\n",
      "82.9\n",
      "-\n",
      "69.5\n",
      "RoG (Llama-2-7B) (Luo et al., 2024)\n",
      "85.7\n",
      "70.8\n",
      "62.6\n",
      "56.2\n",
      "GNN-RAG (Mavromatis & Karypis, 2024)\n",
      "85.7\n",
      "71.3\n",
      "66.8\n",
      "59.4\n",
      "GNN-RAG+RA (Mavromatis & Karypis, 2024)\n",
      "90.7\n",
      "73.5\n",
      "68.7\n",
      "60.4\n",
      "GCR (Llama-3.1-8B + ChatGPT)\n",
      "92.6\n",
      "73.2\n",
      "72.7\n",
      "60.9\n",
      "GCR (Llama-3.1-8B + GPT-4o-mini)\n",
      "92.2\n",
      "74.1\n",
      "75.8\n",
      "61.7\n",
      "2008) is adopted as the knowledge graph for both datasets. To further evaluate the generalizability\n",
      "of GCR, we conduct zero-shot transfer experiments on two new KGQA datasets: CommonsenseQA\n",
      "(CSQA) (Talmor et al., 2019) and MedQA-USMLE (MedQA) (Jin et al., 2021). For CSQA, we use\n",
      "ConceptNet (Speer et al., 2017) as the KG, while for MedQA, we use a medical KG constructed\n",
      "from the Unified Medical Language System (Yasunaga et al., 2021). The details of the datasets are\n",
      "described in Section 7.\n",
      "Baselines. We compare GCR with the 22 baselines grouped into three categories: 1) LLM reasoning\n",
      "methods, 2) graph reasoning methods, and 3) KG-enhanced LLM reasoning methods. The detailed\n",
      "baselines are listed in Section 8.\n",
      "Evaluation Metrics. We adopt Hit and F1 as the evaluation metrics following previous works (Luo\n",
      "et al., 2024; Sun et al., 2024) on WebQSP and CWQ. Hit checks whether any correct answer exists in\n",
      "the generated predictions, while F1 considers the coverage of all answers by balancing the precision\n",
      "and recall of predictions. Because CSQA and MedQA are multiple-choice QA datasets, we adopt\n",
      "accuracy as the evaluation metric.\n",
      "Implementations. For GCR, we use the KG-Trie to index all the reasoning paths within 2 hops\n",
      "starting from question entities. For the LLMs, we use a fine-tuned Llama-3-8B (Meta, 2024) as\n",
      "the KG-specialized LLM. We generate top-10 reasoning paths and hypothesis answers from graph-\n",
      "constrained decoding. We adopt the advanced ChatGPT (OpenAI, 2022) and GPT-4o-mini (OpenAI,\n",
      "2024a) as the general LLMs for inductive reasoning. The detailed hyperparameters and experiment\n",
      "settings are described in Section 9.\n",
      "5.2\n",
      "RQ1: REASONING PERFORMANCE AND EFFICIENCY\n",
      "Main Results. In this section, we compare GCR with other baselines on KGQA benchmarks to\n",
      "evaluate the reasoning performance. From the results shown in Table 1, GCR achieves the best\n",
      "performance on both datasets, outperforming the second-best by 2.1% and 9.1% in terms of Hit on\n",
      "WebQSP and CWQ, respectively. The results demonstrate that GCR can effectively leverage KGs to\n",
      "enhance LLMs and achieve state-of-the-art reasoning performance.\n",
      "Among the LLM reasoning methods, ChatGPT with self-consistency prompts demonstrates the best\n",
      "performance, which indicates the powerful reasoning ability inherent in LLMs. However, their per-\n",
      "formances are still limited by the model size and complex reasoning required over structured data.\n",
      "Graph reasoning methods, such as ReaRev, achieve competitive performance on WebQSP by ex-\n",
      "7\n",
      "Table 2: Efficiency and performance comparison of different methods on WebQSP.\n",
      "Types\n",
      "Methods\n",
      "Hit\n",
      "Avg. Runtime (s)\n",
      "Avg. # LLM Calls\n",
      "Avg. # LLM Tokens\n",
      "Retrieval-based\n",
      "S-Bert\n",
      "66.9\n",
      "0.87\n",
      "1\n",
      "293\n",
      "BGE\n",
      "72.7\n",
      "1.05\n",
      "1\n",
      "357\n",
      "OpenAI-Emb.\n",
      "79.0\n",
      "1.77\n",
      "1\n",
      "330\n",
      "GNN-RAG\n",
      "85.7\n",
      "1.52\n",
      "1\n",
      "414\n",
      "RoG\n",
      "85.7\n",
      "2.60\n",
      "2\n",
      "521\n",
      "Agent-based\n",
      "ToG\n",
      "75.1\n",
      "16.14\n",
      "11.6\n",
      "7,069\n",
      "EffiQA\n",
      "82.9\n",
      "-\n",
      "7.3\n",
      "-\n",
      "Ours\n",
      "GCR\n",
      "92.6\n",
      "3.60\n",
      "2\n",
      "231\n",
      "plicitly modeling the graph structure. But they struggle to generalize across different datasets and\n",
      "underperform on CWQ. In KG+LLM methods, both agent-based methods (e.g., ToG, EffiQA) and\n",
      "retrieval-based methods (e.g., RoG, GNN-RAG) achieve the second-best performance. Neverthe-\n",
      "less, they still suffer from inefficiency and reasoning hallucinations which limit their performance.\n",
      "In contrast, GCR effectively eliminates hallucinations and conducts faithful reasoning by leveraging\n",
      "the structured KG index and graph-constrained decoding.\n",
      "Efficiency Analysis.\n",
      "To show the efficiency of GCR, we compare the average runtime, number of LLM calls, and num-\n",
      "ber of input tokens with retrieval-based and agent-based methods in Table 2. For retrieval-based\n",
      "methods, we compare with dense retrievers (e.g., S-Bert (Reimers & Gurevych, 2019), BGE (Zhang\n",
      "et al., 2023), OpenAI-Emb. (OpenAI, 2024b)) and graph-based retrievers (e.g., GNN-RAG (Mavro-\n",
      "matis & Karypis, 2024), RoG (Luo et al., 2024)), which retrieve reasoning paths from KGs and feed\n",
      "them into LLMs for reasoning answers. For agent-based methods, we compare with ToG (Sun et al.,\n",
      "2024) and EffiQA1 (Dong et al., 2024), which heuristically search on KGs for answers. The detailed\n",
      "settings are described in Section 9.\n",
      "Dense retrievers are most efficient in terms of runtime and LLM calls as they convert all paths into\n",
      "sentences and encode them as embeddings in advance. However, they sacrifice their accuracy in\n",
      "retrieving as they are not designed to encode graph structure. Graph-based retrievers and agent-\n",
      "based methods achieve better performance by considering graph structure; however, they require\n",
      "more time and LLM calls. Specifically, the retrieved graph is fed as inputs to LLMs, which leads to\n",
      "a large number of input tokens. Agent-based methods, like ToG, require more LLM calls and input\n",
      "tokens as the question difficulty increases due to their iterative reasoning process. In contrast, GCR\n",
      "achieves the best performance with a reasonable runtime and number of LLM calls. With the help\n",
      "of KG-Trie, GCR explores multiple reasoning paths at the same time during the graph-constrained\n",
      "decoding, which does not involve additional LLM calls or input tokens and benefits from the parallel\n",
      "GPU computation with low latency. More efficiency analysis under different beam sizes used for\n",
      "graph-constrained decoding can be found in parameter analysis.\n",
      "Table 3: Ablation studies of GCR on two KGQA datasets.\n",
      "Variants\n",
      "WebQSP\n",
      "CWQ\n",
      "F1\n",
      "Precision\n",
      "Recall\n",
      "F1\n",
      "Precision\n",
      "Recall\n",
      "GCR (Llama-3.1-8B + ChatGPT)\n",
      "73.2\n",
      "80.0\n",
      "76.9\n",
      "60.9\n",
      "61.1\n",
      "66.6\n",
      "GCR w/o KG-specialized LLM\n",
      "52.9\n",
      "66.3\n",
      "50.2\n",
      "37.5\n",
      "40.8\n",
      "37.9\n",
      "GCR w/o General LLM\n",
      "57.0\n",
      "58.0\n",
      "70.1\n",
      "39.4\n",
      "32.8\n",
      "64.3\n",
      "Ablation Study. We first conduct an\n",
      "ablation study to analyze the effec-\n",
      "tiveness of the KG-specialized LLM\n",
      "and general LLM in GCR. As shown\n",
      "in Table 3, the full GCR achieves the\n",
      "best performance on both datasets.\n",
      "By removing the KG-specialized LLM, we feed all 2-hop reasoning paths into the general LLM.\n",
      "This results in a significant performance drop, indicating its importance in utilizing reasoning abil-\n",
      "ity to find relevant paths on KGs for reasoning. On the other hand, removing the general LLM\n",
      "and relying solely on answers predicted by KG-specialized LLM leads to a noticeable decrease in\n",
      "precision, due to noises in its predictions. This highlighting the necessity of the general LLM for\n",
      "conducting inductive reasoning over multiple paths to derive final answers.\n",
      "Different LLMs. We further analyze LLMs used for KG-specialized and general LLMs in Table 4.\n",
      "For KG-specialized LLMs, we directly plug the KG-Trie into different LLMs to conduct graph-\n",
      "constrained decoding and use the same general LLM for final reasoning. For general LLMs, we\n",
      "adopt the same reasoning paths generated by KG-specialized LLMs to different LLMs to produce\n",
      "final answers. For zero-shot and few-shot learning, we adopt the original LLMs without fine-tuning,\n",
      "whose prompt templates can be found in Figures 8 and 10.\n",
      "1Since there is no available code for EffiQA, we directly copy the results from the original paper.\n",
      "8\n",
      "Table 4: Comparison of different LLMs used in\n",
      "GCR on WebQSP.\n",
      "Components\n",
      "Learning Types\n",
      "Variants\n",
      "Hit\n",
      "F1\n",
      "KG-specialized\n",
      "LLM\n",
      "Zero-shot\n",
      "Llama-3.1-8B\n",
      "28.25\n",
      "10.32\n",
      "Llama-3.1-70B\n",
      "38.53\n",
      "12.53\n",
      "Few-shot\n",
      "Llama-3.1-8B\n",
      "33.24\n",
      "11.19\n",
      "Llama-3.1-70B\n",
      "41.13\n",
      "13.14\n",
      "Fine-tuned\n",
      "Qwen2-0.5B\n",
      "87.48\n",
      "60.03\n",
      "Qwen2-1.5B\n",
      "89.21\n",
      "62.97\n",
      "Qwen2-7B\n",
      "92.31\n",
      "72.74\n",
      "Llama-2-7B\n",
      "92.55\n",
      "73.23\n",
      "Llama-3.1-8B\n",
      "92.74\n",
      "73.14\n",
      "General LLM\n",
      "Zero-shot\n",
      "Qwen-2-7B\n",
      "86.32\n",
      "67.59\n",
      "Llama-3.1-8B\n",
      "90.24\n",
      "71.19\n",
      "Llama-3.1-70B\n",
      "90.24\n",
      "71.19\n",
      "ChatGPT\n",
      "92.55\n",
      "73.23\n",
      "GPT-4o-mini\n",
      "92.23\n",
      "74.05\n",
      "Results in Table 4 show that a lightweight LLM\n",
      "(0.5B) can outperform a large one (70B) af-\n",
      "ter fine-tuning, indicating the effectiveness of\n",
      "fine-tuning in enhancing the ability of LLMs\n",
      "and make them specialized for KG reason-\n",
      "ing.\n",
      "However, the larger LLMs (e.g., 7B\n",
      "and 8B) still perform better than smaller ones,\n",
      "highlighting the importance of model capac-\n",
      "ity in searching relevant reasoning paths on\n",
      "KGs.\n",
      "Similar trends are observed in gen-\n",
      "eral LLMs where larger models (e.g., GPT-4o-\n",
      "mini and ChatGPT) outperform smaller ones\n",
      "(e.g., Qwen-2-7B and Llama-3.1-8B), show-\n",
      "casing their stronger inductive reasoning abili-\n",
      "ties. This further emphasizes the need of paring\n",
      "powerful general LLMs with lightweight KG-specialized LLMs to achieve better reasoning driven\n",
      "by both of them.\n",
      "1\n",
      "3\n",
      "5\n",
      "10\n",
      "20\n",
      "Graph-constrained decoding beam size K\n",
      "0\n",
      "2\n",
      "4\n",
      "6\n",
      "8\n",
      "Generation Time (s)\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "Answer Coverage (%)\n",
      "Generation Time (s)\n",
      "Hit\n",
      "F1\n",
      "Precision\n",
      "Recall\n",
      "Figure 4: Parameter analysis of beam\n",
      "size K.\n",
      "Parameter Analysis. We first analyze the impact of dif-\n",
      "ferent beam sizes K for graph-constrained decoding on\n",
      "the performance of GCR. We conduct the experiments on\n",
      "WebQSP with different beam sizes of 1, 3, 5, 10, and 20.\n",
      "The results are shown in Figure 4. We observe that the hit\n",
      "and recall of GCR increase with the beam size. Because,\n",
      "with a larger beam size, the LLMs can explore more rea-\n",
      "soning paths and find the correct answers. However, the\n",
      "F1 score, peaks when the beam size is set to 10. This is\n",
      "because the beam size of 10 can provide a balance be-\n",
      "tween the exploration and exploitation of the reasoning\n",
      "paths. When the beam size is set to 20, the performance\n",
      "drops due to the increased complexity of the search space,\n",
      "which may introduce noise and make the reasoning less\n",
      "reliable. This also highlights the importance of using general LLMs to conduct inductive reason-\n",
      "ing over multiple paths to disregard the noise and find the correct answers. Although the graph-\n",
      "constrained decoding benefits from the parallel GPU computation to explore multiple reasoning\n",
      "paths at the same time, the time cost still slightly increases from 1.4s to 7.8s with the increase of\n",
      "the beam size. Thus, we set the beam size to 10 in the experiments to balance the performance and\n",
      "efficiency. We also investigate the impact of L hops paths used for KG-Trie construction in Sec-\n",
      "tion 10.1. The results show that GCR can achieve a good balance between reasoning performance\n",
      "and efficiency by setting L = 2 and K = 10.\n",
      "5.3\n",
      "RQ2: HALLUCINATION ELIMINATION AND FAITHFUL REASONING\n",
      "In this section, we investigate the effectiveness of KG constraints in eliminating hallucinations and\n",
      "ensuring faithful reasoning. We first compare the difference of answer accuracy (Hit) and faithful\n",
      "reasoning ratio by removing KG constraints in graph-constrained decoding. The faithful reasoning\n",
      "ratio is calculated as the percentage of faithful reasoning in correctly predicted answers. We define\n",
      "a reasoning as faithful where the generated reasoning path can be found in KGs, and vice versa.\n",
      "GCR GCR w/o constraint\n",
      "0\n",
      "20\n",
      "40\n",
      "60\n",
      "Answer Hit\n",
      "100.0%\n",
      "62.4%\n",
      "WebQSP\n",
      "Faithful Reasoning\n",
      "Error Reasoning\n",
      "GCR GCR w/o constraint\n",
      "0\n",
      "20\n",
      "40\n",
      "60\n",
      "Answer Hit\n",
      "100.0%\n",
      "48.1%\n",
      "CWQ\n",
      "Figure 5: Analysis of performance and reasoning\n",
      "errors in GCR.\n",
      "From the Figure 5, we can observe that GCR\n",
      "achieves the 100% faithful reasoning ratio on\n",
      "both datasets, which indicates that GCR can\n",
      "eliminate hallucinations and ensure faithful rea-\n",
      "soning during reasoning on KGs. In contrast,\n",
      "when removing KG constraints, both the an-\n",
      "swer accuracy and faithful reasoning decrease\n",
      "significantly on WebQSP. This shows that KG\n",
      "constraints not only improve reasoning by re-\n",
      "ducing the searching space, but also play a cru-\n",
      "cial role in preventing hallucinations for accu-\n",
      "9\n",
      "Table 5: Examples of the faithful reasoning conducted by GCR. Red denotes the incorrect reasoning\n",
      "paths and answers, while bold denotes the correct paths and answers.\n",
      "Case 1: Incorrect answers and hallucinated reasoning paths without constraints.\n",
      "Question\n",
      "Who is niall ferguson ’s wife?\n",
      "Answer\n",
      "Ayaan Hirsi Ali\n",
      "GCR w/o constraint\n",
      "# Reasoning Path: Niall Ferguson →people.person.children →Mabel Rose Ferguson →\n",
      "people.person.parents →Alyssa Mastromonaco\n",
      "#Answer: Alyssa Mastromonaco\n",
      "GCR\n",
      "# Reasoning Path: Niall Ferguson →people.person.children →Thomas Ferguson →peo-\n",
      "ple.person.parents →Ayaan Hirsi Ali\n",
      "#Answer: Ayaan Hirsi Ali\n",
      "Case 2: Correct answers but hallucinated reasoning paths without constraints.\n",
      "Question\n",
      "Where is jamarcus russell from?\n",
      "Answer\n",
      "Mobile\n",
      "GCR w/o constraint\n",
      "# Reasoning Path: JaMarcus Russell →people.person.place of birth →Tampa\n",
      "#Answer: Mobile, Alabama\n",
      "GCR\n",
      "# Reasoning Path: JaMarcus Russell →people.person.place of birth →Mobile\n",
      "#Answer: Mobile\n",
      "rate reasoning. While the answer hit rate on CWQ remains almost unchanged, the ratio of faithful\n",
      "reasoning still decreases to 48.1%. This implies that even if LLMs can produce correct answers, the\n",
      "reasoning process is still prone to hallucinations and cannot be trusted, which is aligned with the\n",
      "findings in previous studies (Nguyen et al., 2024).\n",
      "Case Study. We further provide a case study to illustrate the effectiveness of GCR in eliminating\n",
      "hallucinations and ensuring faithful reasoning. As shown in Table 5, the first case demonstrates that,\n",
      "without constraints, the model generates an incorrect reasoning path leading to an incorrect answer\n",
      "by hallucinating facts such as “Mabel Rose Ferguson is the child of Naill Ferguson and her parent\n",
      "is Alyssa Mastromonaco”. In contrast, GCR generates a faithful reasoning path grounded in KGs\n",
      "that “Naill Ferguson has a child named Thomas Ferguson who has a parent named Ayaan Hirsi Ali”.\n",
      "Based on the paths we can reason the correct answer to the question is “Ayaan Hirsi Ali”. In the\n",
      "second case, although the LLM answers the question correctly, the generated reasoning path is still\n",
      "hallucinated with incorrect facts. Conversely, GCR conducts faithful reasoning with both correct\n",
      "answer and reasoning path. These results demonstrate that GCR can effectively eliminate hallucina-\n",
      "tions and ensure faithful reasoning by leveraging KG constraints in graph-constrained decoding.\n",
      "5.4\n",
      "RQ3: ZERO-SHOT GENERALIZABILITY TO UNSEEN KGS\n",
      "Table 6: Zero-shot transferabil-\n",
      "ity to other KGQA datasets.\n",
      "Model\n",
      "CSQA\n",
      "MedQA\n",
      "ChatGPT\n",
      "79\n",
      "64\n",
      "GCR (ChatGPT)\n",
      "85\n",
      "66\n",
      "GPT-4o-mini\n",
      "91\n",
      "75\n",
      "GCR (GPT-4o-mini)\n",
      "94\n",
      "79\n",
      "In GCR, the knowledge graph is converted into a constraint which\n",
      "is plugged into the decoding process of LLMs. This allows GCR\n",
      "to generalize to unseen KGs without further training. To evaluate\n",
      "the generalizability of GCR, we conduct zero-shot transfer ex-\n",
      "periments on two unseen KGQA datasets: CSQA (Talmor et al.,\n",
      "2019) and MedQA (Jin et al., 2021). Specifically, we use the\n",
      "same KG-specialized LLM (Llama-3.1-8B) trained on Freebase\n",
      "as well as two general LLMs (ChatGP, GPT-4o-mini). During\n",
      "reasoning, we directly plug the KG-Trie constructed from ConceptNet and medical KGs into the\n",
      "GCR to conduct graph-constrained decoding without additional fine-tuning. The results are shown\n",
      "in Table 6.\n",
      "From the results, it is evident that GCR outperforms ChatGPT and GPT-4o-mini in zero-shot per-\n",
      "formance on both datasets. Specifically, GCR shows a 7.6% increase in accuracy on CSQA and a\n",
      "3.1% improvement on MedQA compared to ChatGPT. This highlights the strong zero-shot general-\n",
      "izability of its graph reasoning capabilities to unseen KGs without additional training. However, the\n",
      "improvement on MedQA is not as significant as that on CSQA. We hypothesize this difference may\n",
      "be due to LLMs having more common sense knowledge, which aids in reasoning on common sense\n",
      "knowledge graphs effectively. On the other hand, medical KGs are more specialized and require\n",
      "domain-specific knowledge for reasoning, potentially limiting the generalizability of our method.\n",
      "10\n",
      "6\n",
      "CONCLUSION\n",
      "In this paper, we introduce a novel LLM reasoning paradigm called graph-constrained reasoning\n",
      "(GCR) to eliminate hallucination and ensure faithful reasoning by incorporating structured KGs. To\n",
      "bridge the unstructured reasoning in LLMs with the structured knowledge in KGs, we propose a\n",
      "KG-Trie to encode paths in KGs using a trie-based index. KG-Trie constrains the decoding process\n",
      "to guide a KG-specialized LLM to generate faithful reasoning paths grounded in KGs. By impos-\n",
      "ing constraints, we can not only eliminate hallucination in reasoning but also reduce the reasoning\n",
      "complexity, contributing to more efficient and accurate reasoning. Last, a powerful general LLM is\n",
      "utilized as a complement to inductively reason over multiple reasoning paths to generate the final\n",
      "answer. Extensive experiments demonstrate that GCR excels in faithful reasoning and generalizes\n",
      "well to reason on new KGs without additional fine-tuning.\n",
      "ACKNOWLEDGMENTS\n",
      "We would want to express our sincere gratitude to Yuan-Fang Li for his valuable feedback and\n",
      "suggestions during the preparation of this work.\n",
      "REFERENCES\n",
      "Garima Agrawal, Tharindu Kumarage, Zeyad Alghamdi, and Huan Liu. Mindful-rag: A study of\n",
      "points of failure in retrieval augmented generation. arXiv preprint arXiv:2407.12216, 2024.\n",
      "Kurt Bollacker, Colin Evans, Praveen Paritosh, Tim Sturge, and Jamie Taylor. Freebase: a collab-\n",
      "oratively created graph database for structuring human knowledge. In Proceedings of the 2008\n",
      "ACM SIGMOD international conference on Management of data, pp. 1247–1250, 2008.\n",
      "Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal,\n",
      "Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. Language models are\n",
      "few-shot learners. Advances in Neural Information Processing Systems, 33:1877–1901, 2020.\n",
      "Chen Chen, Yufei Wang, Bing Li, and Kwok-Yan Lam. Knowledge is flat: A seq2seq generative\n",
      "framework for various knowledge graph completion. In Proceedings of the 29th International\n",
      "Conference on Computational Linguistics, pp. 4005–4017, 2022.\n",
      "Nicola De Cao, Gautier Izacard, Sebastian Riedel, and Fabio Petroni. Autoregressive entity retrieval.\n",
      "In International Conference on Learning Representations, 2022.\n",
      "Mohammad Dehghan, Mohammad Alomrani, Sunyam Bagga, David Alfonso-Hermelo, Khalil Bibi,\n",
      "Abbas Ghaddar, Yingxue Zhang, Xiaoguang Li, Jianye Hao, Qun Liu, Jimmy Lin, Boxing Chen,\n",
      "Prasanna Parthasarathi, Mahdi Biparva, and Mehdi Rezagholizadeh. EWEK-QA : Enhanced web\n",
      "and efficient knowledge graph retrieval for citation-based question answering systems. In Lun-\n",
      "Wei Ku, Andre Martins, and Vivek Srikumar (eds.), Proceedings of the 62nd Annual Meeting\n",
      "of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 14169–14187,\n",
      "Bangkok, Thailand, August 2024. Association for Computational Linguistics. URL https:\n",
      "//aclanthology.org/2024.acl-long.764.\n",
      "Zixuan Dong, Baoyun Peng, Yufei Wang, Jia Fu, Xiaodong Wang, Yongxue Shan, and Xin Zhou. Ef-\n",
      "fiqa: Efficient question-answering with strategic multi-model collaboration on knowledge graphs.\n",
      "arXiv preprint arXiv:2406.01238, 2024.\n",
      "Jonathan St BT Evans. Intuition and reasoning: A dual-process perspective. Psychological Inquiry,\n",
      "21(4):313–326, 2010.\n",
      "Marcello Federico, Mauro Cettolo, Fabio Brugnara, and Giuliano Antoniol. Language modelling\n",
      "for efficient beam-search. Computer Speech and Language, 9(4):353–380, 1995.\n",
      "Yanlin Feng, Xinyue Chen, Bill Yuchen Lin, Peifeng Wang, Jun Yan, and Xiang Ren. Scalable multi-\n",
      "hop relational reasoning for knowledge-aware question answering. In Proceedings of the 2020\n",
      "Conference on Empirical Methods in Natural Language Processing (EMNLP), pp. 1295–1309,\n",
      "2020.\n",
      "11\n",
      "Edward Fredkin. Trie memory. Communications of the ACM, 3(9):490–499, 1960.\n",
      "Gaole He, Yunshi Lan, Jing Jiang, Wayne Xin Zhao, and Ji-Rong Wen. Improving multi-hop knowl-\n",
      "edge base question answering by learning intermediate supervision signals. In Proceedings of the\n",
      "14th ACM international conference on web search and data mining, pp. 553–561, 2021.\n",
      "Matthew Douglas Hoffman, Du Phan, David Dohan, Sholto Douglas, Tuan Anh Le, Aaron Parisi,\n",
      "Pavel Sountsov, Charles Sutton, Sharad Vikram, and Rif A Saurous. Training chain-of-thought\n",
      "via latent-variable inference. Advances in Neural Information Processing Systems, 36, 2024.\n",
      "Jie Huang and Kevin Chen-Chuan Chang. Towards reasoning in large language models: A survey.\n",
      "In Findings of the Association for Computational Linguistics: ACL 2023, pp. 1049–1065, 2023.\n",
      "Jie Huang, Xinyun Chen, Swaroop Mishra, Huaixiu Steven Zheng, Adams Wei Yu, Xinying Song,\n",
      "and Denny Zhou.\n",
      "Large language models cannot self-correct reasoning yet.\n",
      "In The Twelfth\n",
      "International Conference on Learning Representations, 2024.\n",
      "Gautier Izacard and ´Edouard Grave. Leveraging passage retrieval with generative models for open\n",
      "domain question answering. In Proceedings of the 16th Conference of the European Chapter of\n",
      "the Association for Computational Linguistics: Main Volume, pp. 874–880, 2021.\n",
      "Jinhao Jiang, Kun Zhou, Xin Zhao, and Ji-Rong Wen. Unikgqa: Unified retrieval and reasoning\n",
      "for solving multi-hop question answering over knowledge graph. In The Eleventh International\n",
      "Conference on Learning Representations, 2022.\n",
      "Jinhao Jiang, Kun Zhou, Zican Dong, Keming Ye, Wayne Xin Zhao, and Ji-Rong Wen. Structgpt: A\n",
      "general framework for large language model to reason over structured data. In Proceedings of the\n",
      "2023 Conference on Empirical Methods in Natural Language Processing, pp. 9237–9251, 2023.\n",
      "Jinhao Jiang, Kun Zhou, Wayne Xin Zhao, Yang Song, Chen Zhu, Hengshu Zhu, and Ji-Rong\n",
      "Wen. Kg-agent: An efficient autonomous agent framework for complex reasoning over knowl-\n",
      "edge graph. arXiv preprint arXiv:2402.11163, 2024.\n",
      "Di Jin, Eileen Pan, Nassim Oufattole, Wei-Hung Weng, Hanyi Fang, and Peter Szolovits. What dis-\n",
      "ease does this patient have? a large-scale open domain question answering dataset from medical\n",
      "exams. Applied Sciences, 11(14):6421, 2021.\n",
      "Shiyang Li, Yifan Gao, Haoming Jiang, Qingyu Yin, Zheng Li, Xifeng Yan, Chao Zhang, and Bing\n",
      "Yin. Graph reasoning for question answering with triplet retrieval. In Findings of the Association\n",
      "for Computational Linguistics: ACL 2023, pp. 3366–3375, 2023.\n",
      "Linhao Luo, Yuan-Fang Li, Gholamreza Haffari, and Shirui Pan. Reasoning on graphs: Faithful and\n",
      "interpretable large language model reasoning. In International Conference on Learning Repre-\n",
      "sentations, 2024.\n",
      "Costas Mavromatis and George Karypis. Rearev: Adaptive reasoning for question answering over\n",
      "knowledge graphs. In Findings of the Association for Computational Linguistics: EMNLP 2022,\n",
      "pp. 2447–2458, 2022.\n",
      "Costas Mavromatis and George Karypis. Gnn-rag: Graph neural retrieval for large language model\n",
      "reasoning. arXiv preprint arXiv:2405.20139, 2024.\n",
      "Meta. Build the future of ai with meta llama 3, 2024. URL https://llama.meta.com/\n",
      "llama3/.\n",
      "Thi Nguyen, Linhao Luo, Fatemeh Shiri, Dinh Phung, Yuan-Fang Li, Thuy-Trang Vu, and Gho-\n",
      "lamreza Haffari. Direct evaluation of chain-of-thought in multi-hop reasoning with knowledge\n",
      "graphs. In Lun-Wei Ku, Andre Martins, and Vivek Srikumar (eds.), Findings of the Association\n",
      "for Computational Linguistics ACL 2024, pp. 2862–2883, Bangkok, Thailand and virtual meeting,\n",
      "August 2024. Association for Computational Linguistics. URL https://aclanthology.\n",
      "org/2024.findings-acl.168.\n",
      "OpenAI. Introducing chatgpt, 2022. URL https://openai.com/index/chatgpt/.\n",
      "12\n",
      "OpenAI. Hello gpt-4o, 2024a. URL https://openai.com/index/hello-gpt-4o/.\n",
      "OpenAI.\n",
      "New embedding models and api updates, 2024b.\n",
      "URL https://openai.com/\n",
      "index/new-embedding-models-and-api-updates/.\n",
      "OpenAI.\n",
      "Learning to reason with llms, 2024c.\n",
      "URL https://openai.com/index/\n",
      "learning-to-reason-with-llms/.\n",
      "Shirui Pan, Linhao Luo, Yufei Wang, Chen Chen, Jiapu Wang, and Xindong Wu. Unifying large\n",
      "language models and knowledge graphs: A roadmap. IEEE Transactions on Knowledge and Data\n",
      "Engineering (TKDE), 2024.\n",
      "Shuofei Qiao, Yixin Ou, Ningyu Zhang, Xiang Chen, Yunzhi Yao, Shumin Deng, Chuanqi Tan, Fei\n",
      "Huang, and Huajun Chen. Reasoning with language model prompting: A survey. In Proceedings\n",
      "of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long\n",
      "Papers), pp. 5368–5393, 2023.\n",
      "Nils Reimers and Iryna Gurevych.\n",
      "Sentence-bert: Sentence embeddings using siamese bert-\n",
      "networks. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language\n",
      "Processing. Association for Computational Linguistics, 11 2019.\n",
      "URL https://arxiv.\n",
      "org/abs/1908.10084.\n",
      "Devendra Singh, Siva Reddy, Will Hamilton, Chris Dyer, and Dani Yogatama. End-to-end training\n",
      "of multi-document reader and retriever for open-domain question answering. Advances in Neural\n",
      "Information Processing Systems, 34:25968–25981, 2021.\n",
      "Robyn Speer, Joshua Chin, and Catherine Havasi. Conceptnet 5.5: An open multilingual graph of\n",
      "general knowledge. In Proceedings of the AAAI conference on artificial intelligence, volume 31,\n",
      "2017.\n",
      "KE Stanovich, RF West, and R Hertwig. Individual differences in reasoning: Implications for the ra-\n",
      "tionality debate?-open peer commentary-the questionable utility of cognitive ability in explaining\n",
      "cognitive illusions. 2000.\n",
      "Yuan Sui, Yufei He, Nian Liu, Xiaoxin He, Kun Wang, and Bryan Hooi.\n",
      "Fidelis: Faithful\n",
      "reasoning in large language model for knowledge graph question answering.\n",
      "arXiv preprint\n",
      "arXiv:2405.13873, 2024.\n",
      "Haitian Sun, Bhuwan Dhingra, Manzil Zaheer, Kathryn Mazaitis, Ruslan Salakhutdinov, and\n",
      "William Cohen. Open domain question answering using early fusion of knowledge bases and\n",
      "text. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Pro-\n",
      "cessing, pp. 4231–4242, 2018.\n",
      "Jiashuo Sun, Chengjin Xu, Lumingyuan Tang, Saizhuo Wang, Chen Lin, Yeyun Gong, Lionel Ni,\n",
      "Heung-Yeung Shum, and Jian Guo. Think-on-graph: Deep and responsible reasoning of large\n",
      "language model on knowledge graph. In The Twelfth International Conference on Learning Rep-\n",
      "resentations, 2024.\n",
      "Alon Talmor and Jonathan Berant. The web as a knowledge-base for answering complex questions.\n",
      "In Proceedings of the 2018 Conference of the North American Chapter of the Association for\n",
      "Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers), pp. 641–\n",
      "651, 2018.\n",
      "Alon Talmor, Jonathan Herzig, Nicholas Lourie, and Jonathan Berant. Commonsenseqa: A question\n",
      "answering challenge targeting commonsense knowledge. In Proceedings of the 2019 Conference\n",
      "of the North American Chapter of the Association for Computational Linguistics: Human Lan-\n",
      "guage Technologies, Volume 1 (Long and Short Papers), pp. 4149–4158, 2019.\n",
      "Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Niko-\n",
      "lay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et al. Llama 2: Open founda-\n",
      "tion and fine-tuned chat models. arXiv preprint arXiv:2307.09288, 2023.\n",
      "13\n",
      "Keheng Wang, Feiyu Duan, Sirui Wang, Peiguang Li, Yunsen Xian, Chuantao Yin, Wenge Rong,\n",
      "and Zhang Xiong. Knowledge-driven cot: Exploring faithful reasoning in llms for knowledge-\n",
      "intensive question answering. arXiv preprint arXiv:2308.13259, 2023.\n",
      "Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc V Le, Ed H Chi, Sharan Narang, Aakanksha\n",
      "Chowdhery, and Denny Zhou. Self-consistency improves chain of thought reasoning in language\n",
      "models. In The Eleventh International Conference on Learning Representations, 2024.\n",
      "Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V Le, Denny\n",
      "Zhou, et al. Chain-of-thought prompting elicits reasoning in large language models. Advances in\n",
      "Neural Information Processing Systems, 35:24824–24837, 2022.\n",
      "Wikipedia contributors. Trie. https://en.wikipedia.org/wiki/Trie, 2024. Accessed:\n",
      "2024-09-11.\n",
      "Zonghan Wu, Shirui Pan, Fengwen Chen, Guodong Long, Chengqi Zhang, and S Yu Philip. A\n",
      "comprehensive survey on graph neural networks. IEEE transactions on neural networks and\n",
      "learning systems, 32(1):4–24, 2020.\n",
      "Xin Xie, Ningyu Zhang, Zhoubo Li, Shumin Deng, Hui Chen, Feiyu Xiong, Mosha Chen, and\n",
      "Huajun Chen. From discrimination to generation: Knowledge graph completion with generative\n",
      "transformer. In Companion Proceedings of the Web Conference 2022, pp. 162–165, 2022.\n",
      "An Yang, Baosong Yang, Binyuan Hui, Bo Zheng, Bowen Yu, Chang Zhou, Chengpeng Li,\n",
      "Chengyuan Li, Dayiheng Liu, Fei Huang, Guanting Dong, Haoran Wei, Huan Lin, Jialong Tang,\n",
      "Jialin Wang, Jian Yang, Jianhong Tu, Jianwei Zhang, Jianxin Ma, Jin Xu, Jingren Zhou, Jinze Bai,\n",
      "Jinzheng He, Junyang Lin, Kai Dang, Keming Lu, Keqin Chen, Kexin Yang, Mei Li, Mingfeng\n",
      "Xue, Na Ni, Pei Zhang, Peng Wang, Ru Peng, Rui Men, Ruize Gao, Runji Lin, Shijie Wang, Shuai\n",
      "Bai, Sinan Tan, Tianhang Zhu, Tianhao Li, Tianyu Liu, Wenbin Ge, Xiaodong Deng, Xiaohuan\n",
      "Zhou, Xingzhang Ren, Xinyu Zhang, Xipin Wei, Xuancheng Ren, Yang Fan, Yang Yao, Yichang\n",
      "Zhang, Yu Wan, Yunfei Chu, Yuqiong Liu, Zeyu Cui, Zhenru Zhang, and Zhihao Fan. Qwen2\n",
      "technical report. arXiv preprint arXiv:2407.10671, 2024a.\n",
      "Rui Yang, Haoran Liu, Qingcheng Zeng, Yu He Ke, Wanxin Li, Lechao Cheng, Qingyu Chen, James\n",
      "Caverlee, Yutaka Matsuo, and Irene Li. Kg-rank: Enhancing large language models for medical\n",
      "qa with knowledge graphs and ranking techniques. arXiv preprint arXiv:2403.05881, 2024b.\n",
      "Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Tom Griffiths, Yuan Cao, and Karthik\n",
      "Narasimhan. Tree of thoughts: Deliberate problem solving with large language models. Ad-\n",
      "vances in Neural Information Processing Systems, 36, 2024.\n",
      "Michihiro Yasunaga, Hongyu Ren, Antoine Bosselut, Percy Liang, and Jure Leskovec. Qa-gnn:\n",
      "Reasoning with language models and knowledge graphs for question answering. In Proceedings\n",
      "of the 2021 Conference of the North American Chapter of the Association for Computational\n",
      "Linguistics: Human Language Technologies, pp. 535–546, 2021.\n",
      "Wen-tau Yih, Matthew Richardson, Christopher Meek, Ming-Wei Chang, and Jina Suh. The value\n",
      "of semantic parse labeling for knowledge base question answering. In Proceedings of the 54th\n",
      "Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), pp.\n",
      "201–206, 2016.\n",
      "Ping Yu, Tianlu Wang, Olga Golovneva, Badr AlKhamissi, Siddharth Verma, Zhijing Jin, Gargi\n",
      "Ghosh, Mona Diab, and Asli Celikyilmaz. Alert: Adapting language models to reasoning tasks.\n",
      "arXiv preprint arXiv:2212.08286, 2022.\n",
      "Jing Zhang, Xiaokang Zhang, Jifan Yu, Jian Tang, Jie Tang, Cuiping Li, and Hong Chen. Subgraph\n",
      "retrieval enhanced model for multi-hop knowledge base question answering. In Proceedings of the\n",
      "60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),\n",
      "pp. 5773–5784, 2022.\n",
      "Peitian Zhang, Shitao Xiao, Zheng Liu, Zhicheng Dou, and Jian-Yun Nie. Retrieve anything to\n",
      "augment large language models. arXiv preprint arXiv:2310.07554, 2023.\n",
      "14\n",
      "Yuqi Zhu, Shuofei Qiao, Yixin Ou, Shumin Deng, Ningyu Zhang, Shiwei Lyu, Yue Shen, Lei Liang,\n",
      "Jinjie Gu, and Huajun Chen. Knowagent: Knowledge-augmented planning for llm-based agents.\n",
      "arXiv preprint arXiv:2403.03101, 2024.\n",
      "Appendix\n",
      "Table of Contents\n",
      "7\n",
      "Datasets\n",
      "15\n",
      "8\n",
      "Baselines\n",
      "16\n",
      "9\n",
      "Implementation Details and Experiment Settings\n",
      "17\n",
      "10 Additional Experiment Results\n",
      "19\n",
      "10.1 Performance on Different Hops . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "19\n",
      "11 Templates and Prompts\n",
      "19\n",
      "7\n",
      "DATASETS\n",
      "KGQA Datasets. To compare the reasoning performance with existing methods, we use two bench-\n",
      "mark KGQA datasets in this study: WebQuestionSP (WebQSP) (Yih et al., 2016) and Complex We-\n",
      "bQuestions (CWQ) (Talmor & Berant, 2018). To ensure fairness, we adopt the same train and test\n",
      "splits as previous works (Jiang et al., 2022; Luo et al., 2024). Details of the datasets can be found in\n",
      "Table 7.\n",
      "Both WebQSP and CWQ can be reasoned using Freebase KGs2 (Bollacker et al., 2008). To reduce\n",
      "the size of the KGs, we use a subgraph of Freebase by extracting all triples that start from question\n",
      "entities within the maximum reasoning hops provided by previous works3 (Luo et al., 2024). The\n",
      "statistics of the knowledge graphs are shown in Table 9.\n",
      "Fine-tuning Datasets. To enhance the KG reasoning ability of LLMs, we construct fine-tuning\n",
      "datasets by generating reasoning paths from the KGs. Specifically, we adopt the training split of\n",
      "WebQSP and CWQ, which contain 2,826 and 27,639 question-answer pairs, respectively. For each\n",
      "question, we find all the shortest reasoning paths on KGs that connect the question entity to the\n",
      "answer entity. We then convert the reasoning paths into formatted strings and pair them with the\n",
      "question-answer pairs with the template shown in Figure 8 to form the fine-tuning datasets. Since\n",
      "there could be multiple reasoning paths for a question, we generate multiple training instances paired\n",
      "with different reasoning paths for each question-answer pair. The fine-tuning datasets contain 28,307\n",
      "and 181,602 question-reasoning path-answer triples for WebQSP and CWQ, respectively. The statis-\n",
      "tics of the fine-tuning datasets are shown in Table 8.\n",
      "Zero-shot Generalization Datasets.\n",
      "To evaluate the transferability of GCR, we further select\n",
      "two new KGQA datasets4: CommonsenseQA (CSQA) (Talmor et al., 2019) and MedQA-USMLE\n",
      "(MedQA) (Jin et al., 2021). CSQA is a 5-way multiple choice QA dataset that involves reasoning\n",
      "with commonsense knowledge. MedQA is a 4-way multiple choice QA task that requires biomed-\n",
      "ical and clinical knowledge. For CSQA, we use the ConceptNet (Speer et al., 2017), which is a\n",
      "general-purpose KG that contains commonsense knowledge. For MedQA, we use a medical KG\n",
      "2https://github.com/microsoft/FastRDFStore\n",
      "3WebQSP: https://huggingface.co/datasets/rmanluo/RoG-webqsp, CWQ: https://\n",
      "huggingface.co/datasets/rmanluo/RoG-cwq\n",
      "4https://github.com/michiyasunaga/qagnn\n",
      "15\n",
      "constructed from the Unified Medical Language System (Yasunaga et al., 2021). The statistics of\n",
      "the knowledge graphs are shown in Table 9. We respectively select 100 questions from each dataset.\n",
      "For each question, following previous studies (Feng et al., 2020; Yasunaga et al., 2021), a 2-hop\n",
      "subgraph is extracted from the KGs to form the zero-shot generalization datasets.\n",
      "Table 7: Statistics of datasets.\n",
      "Dataset\n",
      "Dataset Statistics\n",
      "Statistics of Answer Numbers\n",
      "#Train\n",
      "#Test\n",
      "#Ans = 1\n",
      "2 ≥#Ans ≤4\n",
      "5 ≥#Ans ≤9\n",
      "#Ans ≥10\n",
      "WebQSP\n",
      "2,826\n",
      "1,628\n",
      "51.2%\n",
      "27.4%\n",
      "8.3%\n",
      "12.1%\n",
      "CWQ\n",
      "27,639\n",
      "3,531\n",
      "70.6%\n",
      "19.4%\n",
      "6%\n",
      "4%\n",
      "Table 8: Statistics of fine-tuning datasets for graph-constrained decoding.\n",
      "Total\n",
      "WebQSP\n",
      "CWQ\n",
      "209,909\n",
      "28,307\n",
      "181,602\n",
      "Table 9: Statistics of constructed knowledge graphs.\n",
      "KG\n",
      "#Entities\n",
      "#Relations\n",
      "#Triples\n",
      "Freebase\n",
      "2,566,291\n",
      "7,058\n",
      "8,309,195\n",
      "ConceptNet\n",
      "799,273\n",
      "17\n",
      "2,151,303\n",
      "MedKG\n",
      "9,958\n",
      "15\n",
      "49,974\n",
      "8\n",
      "BASELINES\n",
      "We compare GCR with the 22 baselines grouped into three categories: 1) LLM reasoning methods,\n",
      "2) graph reasoning methods, and 3) KG-enhanced LLM reasoning methods. The details of each\n",
      "baseline are described as follows.\n",
      "LLM reasoning methods only rely on LLMs for reasoning without utilizing external KGs. We\n",
      "include both the vanilla LLMs with different sizes and the LLMs with advanced reasoning mecha-\n",
      "nisms. Specifically, we consider the following baselines:\n",
      "• Qwen2-0.5B/1.5B.7B (Yang et al., 2024a) provides a series of pre-trained LLMs with dif-\n",
      "ferent sizes, including 0.5B, 1.5B, and 7B parameters.\n",
      "• Llama-2-7B (Touvron et al., 2023) is a large-scale LLM pre-trained on a diverse range of\n",
      "tasks.\n",
      "• Llama-3.1-8B (Meta, 2024) is the updated version of Llama-2 with more powerful reason-\n",
      "ing capabilities.\n",
      "• ChatGPT (OpenAI, 2022) is a powerful closed-source LLM that could follow instructions\n",
      "to conduct complex tasks.\n",
      "• GPT-4o-mini (OpenAI, 2024a) is the new flagship model of OpenAI that could reason\n",
      "across different modalities and tasks.\n",
      "• Few-shot prompt (Brown et al., 2020) is a few-shot learning method that provides LLMs\n",
      "with a few examples in the prompts to conduct reasoning.\n",
      "• CoT (Wei et al., 2022) is a chain-of-thought reasoning method that prompts LLMs to gen-\n",
      "erate a chain of reasoning steps.\n",
      "• Self-consistency (Wang et al., 2024) generates multiple reasoning paths and selects the\n",
      "most consistent answer.\n",
      "16\n",
      "Graph reasoning methods focus on reasoning on KGs using graph neural networks (GNNs) (Wu\n",
      "et al., 2020) or graph-based reasoning mechanisms. We include the following baselines:\n",
      "• GraftNet (Sun et al., 2018) is a graph-based reasoning method that retrieves relevant sub-\n",
      "graphs from KGs with entity linking.\n",
      "• NSM (He et al., 2021) utilizes the sequential model to mimic the multi-hop reasoning\n",
      "process on KGs.\n",
      "• SR+NSM (Zhang et al., 2022) proposes a relation-path retrieval to retrieve subgraphs for\n",
      "multi-hop reasoning.\n",
      "• ReaRev (Mavromatis & Karypis, 2022) is a GNN-based method that reasons on KGs by\n",
      "considering complex graph information.\n",
      "KG-enhanced LLM reasoning methods incorporate KGs to enhance the reasoning abilities of\n",
      "LLMs which can be further divided into retrieval-based and agent-based paradigms. We include the\n",
      "following baselines:\n",
      "Retrieval-based methods retrieve relevant facts from KGs with an external retriever and then feed\n",
      "them into the inputs of LLMs for reasoning:\n",
      "• KD-CoT (Wang et al., 2023) retrieves relevant knowledge from KGs to generate faithful\n",
      "reasoning plans for LLMs.\n",
      "• EWEK-QA (Dehghan et al., 2024) enriches the retrieved knowledge by searching from\n",
      "both KGs and web.\n",
      "• RoG (Luo et al., 2024) proposes a planning-retrieval-reasoning framework that retrieves\n",
      "reasoning paths from KGs to guide LLMs conducting faithful reasoning.\n",
      "• GNN-RAG (Mavromatis & Karypis, 2024) adopts a lightweight graph neural network to\n",
      "effectively retrieve from KGs.\n",
      "• GNN-RAG+RA (Mavromatis & Karypis, 2024) combines the retrieval results of both RoG\n",
      "and GNN-RAG to enhance the reasoning performance.\n",
      "Agent-based methods treat LLMs as agents that iteratively interact with KGs to find reasoning paths\n",
      "and answers:\n",
      "• ToG (Sun et al., 2024) conducts the reasoning on KGs by exploring multiple paths and\n",
      "concludes the final answer by aggregating the evidence from them.\n",
      "• EffiQA (Jiang et al., 2024) proposes an efficient agent-based method to reason on KGs.\n",
      "9\n",
      "IMPLEMENTATION DETAILS AND EXPERIMENT SETTINGS\n",
      "In this section, we will detail the implementation of GCR as well as the experiment settings.\n",
      "Fine-tuning KG-specialized LLMs. We fine-tune several lightweight LLMs ranging from 0.5B to\n",
      "8B (Yang et al., 2024a; Touvron et al., 2023; Meta, 2024) on the fine-tuning datasets for 3 epochs.\n",
      "The batch size is set to 4 and the learning rate is set to 2e-5. We use the cosine learning rate scheduler\n",
      "policy with the warmup ratio set to 0.03. The training is conducted on 2 A100-80G GPUs for each\n",
      "model. The training time and memory usage are shown in Table 10.\n",
      "KGQA Experiment Settings. The KGQA experiment shown in Table 1 aims to compare the rea-\n",
      "soning performance of GCR with existing methods. For our method, we use the fine-tuned Llama-\n",
      "3.1-8B as KG-specialized LLMs, the general LLM is selected as ChatGPT and GPT-4o-mini. The\n",
      "KG-Trie is constructed from the subgraph of Freebase KGs. The maximum reasoning hops are set\n",
      "to 2 for both WebQSP and CWQ. The beam size is set to 10 for graph-constrained decoding. For\n",
      "vanilla LLMs baselines, we use the zero-shot prompting to ask the models to answer the questions.\n",
      "For other baselines, we strictly check whether the original papers follow the same settings and copy\n",
      "the results for fair comparison.\n",
      "Efficiency Analysis Settings. The efficiency analysis shown in Table 2 aims to compare the effi-\n",
      "ciency and performance of different methods on WebQSP. For GCR, we use the same settings as the\n",
      "17\n",
      "Table 10: Training time and memory usage for different KG-specialized LLMs.\n",
      "Model\n",
      "Time\n",
      "Mem. Usage per GPU\n",
      "Qwen2-0.5B\n",
      "3.47h\n",
      "10G\n",
      "Qwen2-1.5B\n",
      "4.11h\n",
      "25G\n",
      "Qwen2-7B\n",
      "14.37h\n",
      "81G\n",
      "Llama-2-7B\n",
      "13.93h\n",
      "80G\n",
      "Llama-3.1-8B\n",
      "14.52h\n",
      "85G\n",
      "KGQA experiment. For dense retriever methods (e.g., S-Bert (Reimers & Gurevych, 2019), BGE\n",
      "(Zhang et al., 2023), OpenAI-Emb. (OpenAI, 2024b)), we first search all paths within 2-hops on the\n",
      "KGs which are formatted as sentences with the template in Figure 7. Then, we adopt the embedding\n",
      "model to encode the path sentences as embeddings which are stored in a vector database. During in-\n",
      "ference, we retrieve 10 paths from the vector database with the question as query and feed them into\n",
      "the LLMs for reasoning. For GNN-RAG (Mavromatis & Karypis, 2024) and RoG (Luo et al., 2024),\n",
      "we strictly follow the original papers to retrieve reasoning paths and conduct the experiments. For\n",
      "agent-based methods (e.g., ToG (Sun et al., 2024)), we use the same settings detailed in the original\n",
      "papers. For EffiQA (Jiang et al., 2024), since there is no available code, we directly copy the results\n",
      "from the original paper.\n",
      "The average runtime is measured by the time taken to answer the questions. The average number\n",
      "of LLM calls is the number of times the LLMs are called to answer the questions. The average\n",
      "number of LLM tokens is the number of tokens inputted into LLMs to answer the questions, such\n",
      "as questions and retrieved reasoning paths. The experiments are conducted on a single A100-80G\n",
      "GPU for each method.\n",
      "Ablation Study. In ablation study, we first try to analyze the effectiveness of different components in\n",
      "GCR. We conduct the experiments on WebQSP and CWQ datasets. By removing the KG-specialized\n",
      "LLM (w/o KG-specialized LLM), we search all the 2-hop paths starting from question entities and\n",
      "feed them into the general LLMs for reasoning. By removing the general LLM (w/o general LLM),\n",
      "we directly use the hypothesis answers generated by the KG-specialized LLMs as the final answers.\n",
      "Different LLMs. We also analyze the different LLMs used for KG-specialized LLMs and general\n",
      "LLMs on WebQSP. For KG-specialized LLMs, we first use the vanilla LLMs with different learning\n",
      "types (i.e., zero-shot and few-shot prompting). For zero-shot prompting, we directly ask the models\n",
      "to generate the reasoning paths with the constraints. For few-shot prompting, we provide the models\n",
      "with a few examples in the prompts to conduct path generation. Detailed prompts can be found in\n",
      "Figures 8 and 10. Then, we fine-tune the lightweight LLMs with different sizes (0.5B to 8B) on the\n",
      "graph-constrained decoding task. For general LLMs, we use the vanilla LLMs to directly conduct\n",
      "reasoning over multiple reasoning paths. The detailed reasoning prompts can be found in Figure 9.\n",
      "Parameter Analysis. We first analyze the performance of GCR with different beam sizes for graph-\n",
      "constrained decoding. We conduct the experiments on the WebQSP datasets with beam sizes of 1, 3,\n",
      "5, 10, and 20. Then, we analyze the performance of GCR with different hops of paths encoded in the\n",
      "KG-Trie. We conduct the experiments on the WebQSP datasets with maximum paths hops ranging\n",
      "from 1 to 4.\n",
      "Faithful Reasoning Analysis. We investigate the effect of the KG constraints on ensuring faithful\n",
      "reasoning. We adopt the fine-tuned Llama-3.1-8B as KG-specialized LLMs. Then, we compare\n",
      "the faithful reasoning rate and answer hit of GCR with and without the KG constraints in graph-\n",
      "constrained decoding. The faithful reasoning rate is the percentage of the faithful reasoning in the\n",
      "correctly predicted answers. A reasoning path is considered faithful if it can be found in the KGs,\n",
      "and vice versa. The answer hit is the percentage of the correct answers in the predictions.\n",
      "Zero-shot Generalization Analysis. We evaluate the transferability of GCR on two zero-shot gen-\n",
      "eralization datasets: CSQA and MedQA. We use the fine-tuned Llama-3.1-8B as KG-specialized\n",
      "LLMs and ChatGPT as well as GPT-4o-mini as the general LLMs. The KG-Trie is constructed\n",
      "from the subgraph of ConceptNet and MedKG. The maximum reasoning hops are set to 2 for both\n",
      "datasets. The beam size is set to 10 for graph-constrained decoding. For vanilla LLMs baselines\n",
      "18\n",
      "(i.e., ChatGPT and GPT-4o-mini), we use the zero-shot prompting to ask the models to answer the\n",
      "questions.\n",
      "10\n",
      "ADDITIONAL EXPERIMENT RESULTS\n",
      "10.1\n",
      "PERFORMANCE ON DIFFERENT HOPS\n",
      "In this section, we analyze the impact of different hops of reasoning paths on the performance of\n",
      "GCR. We conduct the experiments on WebQSP with different maximum hops of reasoning paths\n",
      "encoded in the KG-Trie. The results are shown in Figure 6. We observe that the performance\n",
      "of GCR increases with the number of hops of reasoning paths. The performance peaks when the\n",
      "maximum hops of reasoning paths are set to 2. This is because the 2-hop paths can provide sufficient\n",
      "information for the LLMs to conduct reasoning. When the hops are set to 3 or 4, the performance\n",
      "drops due to the increased complexity of the reasoning paths, which may introduce noise and make\n",
      "the reasoning less reliable. Additionally, the size of the KG-Trie slightly increases from 0.5 MB to\n",
      "7.5 MB with the increase of the hops from 1 to 4. This indicates that the KG-Trie can be efficiently\n",
      "constructed with a small size and guide the LLMs to reason on graphs effectively.\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "KG-Trie Path Length L\n",
      "0\n",
      "2\n",
      "4\n",
      "6\n",
      "Avg. KG-Trie size (MB)\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "Answer Coverage (%)\n",
      "Avg. KG-Trie size (MB)\n",
      "Hit\n",
      "F1\n",
      "Precision\n",
      "Recall\n",
      "Figure 6: Parameter analysis of path hop L for KG-Trie construction on WebQSP.\n",
      "11\n",
      "TEMPLATES AND PROMPTS\n",
      "In this section, we illustrate all the templates and prompts used in the experiments.\n",
      "Path Sentence Template. The template for converting reasoning paths into natural language sen-\n",
      "tences is shown in Figure 7, where the e∗and r∗denotes the entities and relations in a reasoning\n",
      "path wz = e0\n",
      "r1\n",
      "−→e1\n",
      "r2\n",
      "−→. . .\n",
      "rl\n",
      "−→el,\n",
      "Path Sentence Template\n",
      "<PATH> e1 →r1 →e2 →. . . →rl →el </PATH>\n",
      "Figure 7: The template for converting reasoning paths into formatted sentences.\n",
      "Graph-constrained Decoding Prompt. The prompt for graph-constrained decoding is shown in\n",
      "Figure 8, where the question and mentioned entities are provided to the LLMs to generate rea-\n",
      "soning paths and hypothesis answers. In the fine-tuning datasets, the supervised LLM outputs are\n",
      "constructed from the ground-truth answers and reasoning paths extracted from the KGs.\n",
      "19\n",
      "Graph-constrained Decoding Prompt\n",
      "============================= Prompt Input ================================\n",
      "Reasoning path is a sequence of triples in the KG that connects the topic entities in the question to\n",
      "answer entities. Given a question, please generate some reasoning paths in the KG starting from the\n",
      "topic entities to answer the question.\n",
      "# Question:\n",
      "<Question>\n",
      "# Topic entities:\n",
      "<Question Entities>\n",
      "============================= LLM Output ================================\n",
      "# Reasoning Path:\n",
      "<PATH> <Reasoning Path> </PATH>\n",
      "# Answer:\n",
      "<Hypothesis Answer>\n",
      "Figure 8: The prompt template for graph-constrained decoding.\n",
      "The few-shot prompt template for graph-constrained decoding is shown in Figure 10. We provide a\n",
      "few examples in the prompts to guide the LLMs to generate reasoning paths. Since the LLMs with\n",
      "few-shot prompt learning are not fine-tuned on the graph-constrained decoding task, we only apply\n",
      "the constraint to generate reasoning paths.\n",
      "Graph Inductive Reasoning Prompt. The prompt for graph inductive reasoning is shown in Fig-\n",
      "ure 9. We adopt the graph-constrained decoding to generate K reasoning paths and hypothesis\n",
      "answers for each question. The reasoning paths and hypothesis answers are provided to the general\n",
      "LLMs to answer the questions without fine-tuning.\n",
      "Graph Inductive Reasoning Prompt\n",
      "============================= Prompt Input ================================\n",
      "# Reasoning Paths:\n",
      "<Reasoning Path 1><Hypothesis Answer 1>\n",
      ". . .\n",
      "<Reasoning Path K><Hypothesis Answer K>\n",
      "# Question:\n",
      "<Question>\n",
      "Based on the reasoning paths, please answer the given question. Please keep the answer as simple as\n",
      "possible and only return answers. Please return each answer in a new line.\n",
      "============================= LLM Output ================================\n",
      "<Answer 1>\n",
      "<Answer 2>\n",
      ". . .\n",
      "Figure 9: The prompt template for graph inductive reasoning.\n",
      "20\n",
      "Few-shot Graph-constrained Decoding Prompt\n",
      "============================= Prompt Input ================================\n",
      "Reasoning path is a sequence of triples in the KG that connects the topic entities in the question to\n",
      "answer entities. Given a question, please generate some reasoning paths in the KG starting from the\n",
      "topic entities to answer the question.\n",
      "Example 1\n",
      "# Question:\n",
      "<Question>\n",
      "# Topic entities:\n",
      "<Question Entities>\n",
      "# Reasoning Path:\n",
      "<Reasoning Path>\n",
      "Example 2\n",
      "# Question:\n",
      "<Question>\n",
      "# Topic entities:\n",
      "<Question Entities>\n",
      "# Reasoning Path:\n",
      "<Reasoning Path>\n",
      "Example 3\n",
      "# Question:\n",
      "<Question>\n",
      "# Topic entities:\n",
      "<Question Entities>\n",
      "# Reasoning Path:\n",
      "<Reasoning Path>\n",
      "Input\n",
      "# Question:\n",
      "<Question>\n",
      "# Topic entities:\n",
      "<Question Entities>\n",
      "============================= LLM Output ================================\n",
      "# Reasoning Path:\n",
      "<Reasoning Path>\n",
      "Figure 10: The few-shot prompt template for graph-constrained decoding.\n",
      "21\n",
      "' metadata={'Published': '2024-10-16', 'Title': 'Graph-constrained Reasoning: Faithful Reasoning on Knowledge Graphs with Large Language Models', 'Authors': 'Linhao Luo, Zicheng Zhao, Chen Gong, Gholamreza Haffari, Shirui Pan', 'Summary': 'Large language models (LLMs) have demonstrated impressive reasoning\\nabilities, but they still struggle with faithful reasoning due to knowledge\\ngaps and hallucinations. To address these issues, knowledge graphs (KGs) have\\nbeen utilized to enhance LLM reasoning through their structured knowledge.\\nHowever, existing KG-enhanced methods, either retrieval-based or agent-based,\\nencounter difficulties in accurately retrieving knowledge and efficiently\\ntraversing KGs at scale. In this work, we introduce graph-constrained reasoning\\n(GCR), a novel framework that bridges structured knowledge in KGs with\\nunstructured reasoning in LLMs. To eliminate hallucinations, GCR ensures\\nfaithful KG-grounded reasoning by integrating KG structure into the LLM\\ndecoding process through KG-Trie, a trie-based index that encodes KG reasoning\\npaths. KG-Trie constrains the decoding process, allowing LLMs to directly\\nreason on graphs and generate faithful reasoning paths grounded in KGs.\\nAdditionally, GCR leverages a lightweight KG-specialized LLM for\\ngraph-constrained reasoning alongside a powerful general LLM for inductive\\nreasoning over multiple reasoning paths, resulting in accurate reasoning with\\nzero reasoning hallucination. Extensive experiments on several KGQA benchmarks\\ndemonstrate that GCR achieves state-of-the-art performance and exhibits strong\\nzero-shot generalizability to unseen KGs without additional training.'}\n"
     ]
    }
   ],
   "source": [
    "docs = loader.load()\n",
    "print(docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
